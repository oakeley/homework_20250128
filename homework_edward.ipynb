{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "429ba545-69d4-4918-a641-b4deada6a3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "DuelingDQN(\n",
      "  (shared): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (advantage): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      "  (value): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "500: reward: -500.00, mean_100: -500.00, episodes: 1, epsilon: 0.995\n",
      "1000: reward: -500.00, mean_100: -500.00, episodes: 2, epsilon: 0.990\n",
      "1500: reward: -500.00, mean_100: -500.00, episodes: 3, epsilon: 0.985\n",
      "2000: reward: -500.00, mean_100: -500.00, episodes: 4, epsilon: 0.980\n",
      "2500: reward: -500.00, mean_100: -500.00, episodes: 5, epsilon: 0.975\n",
      "3000: reward: -500.00, mean_100: -500.00, episodes: 6, epsilon: 0.970\n",
      "3500: reward: -500.00, mean_100: -500.00, episodes: 7, epsilon: 0.965\n",
      "4000: reward: -500.00, mean_100: -500.00, episodes: 8, epsilon: 0.960\n",
      "4500: reward: -500.00, mean_100: -500.00, episodes: 9, epsilon: 0.955\n",
      "5000: reward: -500.00, mean_100: -500.00, episodes: 10, epsilon: 0.950\n",
      "5500: reward: -500.00, mean_100: -500.00, episodes: 11, epsilon: 0.945\n",
      "6000: reward: -500.00, mean_100: -500.00, episodes: 12, epsilon: 0.940\n",
      "6500: reward: -500.00, mean_100: -500.00, episodes: 13, epsilon: 0.935\n",
      "7000: reward: -500.00, mean_100: -500.00, episodes: 14, epsilon: 0.930\n",
      "7500: reward: -500.00, mean_100: -500.00, episodes: 15, epsilon: 0.925\n",
      "8000: reward: -500.00, mean_100: -500.00, episodes: 16, epsilon: 0.920\n",
      "8500: reward: -500.00, mean_100: -500.00, episodes: 17, epsilon: 0.915\n",
      "9000: reward: -500.00, mean_100: -500.00, episodes: 18, epsilon: 0.910\n",
      "9500: reward: -500.00, mean_100: -500.00, episodes: 19, epsilon: 0.905\n",
      "10000: reward: -500.00, mean_100: -500.00, episodes: 20, epsilon: 0.900\n",
      "10500: reward: -500.00, mean_100: -500.00, episodes: 21, epsilon: 0.895\n",
      "11000: reward: -500.00, mean_100: -500.00, episodes: 22, epsilon: 0.890\n",
      "11500: reward: -500.00, mean_100: -500.00, episodes: 23, epsilon: 0.885\n",
      "12000: reward: -500.00, mean_100: -500.00, episodes: 24, epsilon: 0.880\n",
      "12500: reward: -500.00, mean_100: -500.00, episodes: 25, epsilon: 0.875\n",
      "13000: reward: -500.00, mean_100: -500.00, episodes: 26, epsilon: 0.870\n",
      "13500: reward: -500.00, mean_100: -500.00, episodes: 27, epsilon: 0.865\n",
      "14000: reward: -500.00, mean_100: -500.00, episodes: 28, epsilon: 0.860\n",
      "14500: reward: -500.00, mean_100: -500.00, episodes: 29, epsilon: 0.855\n",
      "14935: reward: -434.00, mean_100: -497.80, episodes: 30, epsilon: 0.851\n",
      "15435: reward: -500.00, mean_100: -497.87, episodes: 31, epsilon: 0.846\n",
      "15935: reward: -500.00, mean_100: -497.94, episodes: 32, epsilon: 0.841\n",
      "16435: reward: -500.00, mean_100: -498.00, episodes: 33, epsilon: 0.836\n",
      "16935: reward: -500.00, mean_100: -498.06, episodes: 34, epsilon: 0.831\n",
      "17435: reward: -500.00, mean_100: -498.11, episodes: 35, epsilon: 0.826\n",
      "17784: reward: -348.00, mean_100: -493.94, episodes: 36, epsilon: 0.822\n",
      "18284: reward: -500.00, mean_100: -494.11, episodes: 37, epsilon: 0.817\n",
      "18784: reward: -500.00, mean_100: -494.26, episodes: 38, epsilon: 0.812\n",
      "19232: reward: -447.00, mean_100: -493.05, episodes: 39, epsilon: 0.808\n",
      "19732: reward: -500.00, mean_100: -493.23, episodes: 40, epsilon: 0.803\n",
      "20205: reward: -472.00, mean_100: -492.71, episodes: 41, epsilon: 0.798\n",
      "20472: reward: -266.00, mean_100: -487.31, episodes: 42, epsilon: 0.795\n",
      "20939: reward: -466.00, mean_100: -486.81, episodes: 43, epsilon: 0.791\n",
      "21365: reward: -425.00, mean_100: -485.41, episodes: 44, epsilon: 0.786\n",
      "21618: reward: -252.00, mean_100: -480.22, episodes: 45, epsilon: 0.784\n",
      "21970: reward: -351.00, mean_100: -477.41, episodes: 46, epsilon: 0.780\n",
      "22470: reward: -500.00, mean_100: -477.89, episodes: 47, epsilon: 0.775\n",
      "22970: reward: -500.00, mean_100: -478.35, episodes: 48, epsilon: 0.770\n",
      "23470: reward: -500.00, mean_100: -478.80, episodes: 49, epsilon: 0.765\n",
      "23935: reward: -464.00, mean_100: -478.50, episodes: 50, epsilon: 0.761\n",
      "24435: reward: -500.00, mean_100: -478.92, episodes: 51, epsilon: 0.756\n",
      "24934: reward: -498.00, mean_100: -479.29, episodes: 52, epsilon: 0.751\n",
      "25346: reward: -411.00, mean_100: -478.00, episodes: 53, epsilon: 0.747\n",
      "25694: reward: -347.00, mean_100: -475.57, episodes: 54, epsilon: 0.743\n",
      "25934: reward: -239.00, mean_100: -471.27, episodes: 55, epsilon: 0.741\n",
      "26255: reward: -320.00, mean_100: -468.57, episodes: 56, epsilon: 0.737\n",
      "26558: reward: -302.00, mean_100: -465.65, episodes: 57, epsilon: 0.734\n",
      "26771: reward: -212.00, mean_100: -461.28, episodes: 58, epsilon: 0.732\n",
      "27160: reward: -388.00, mean_100: -460.03, episodes: 59, epsilon: 0.728\n",
      "27452: reward: -291.00, mean_100: -457.22, episodes: 60, epsilon: 0.725\n",
      "27677: reward: -224.00, mean_100: -453.39, episodes: 61, epsilon: 0.723\n",
      "28177: reward: -500.00, mean_100: -454.15, episodes: 62, epsilon: 0.718\n",
      "28399: reward: -221.00, mean_100: -450.44, episodes: 63, epsilon: 0.716\n",
      "28638: reward: -238.00, mean_100: -447.12, episodes: 64, epsilon: 0.714\n",
      "28959: reward: -320.00, mean_100: -445.17, episodes: 65, epsilon: 0.710\n",
      "29459: reward: -500.00, mean_100: -446.00, episodes: 66, epsilon: 0.705\n",
      "29759: reward: -299.00, mean_100: -443.81, episodes: 67, epsilon: 0.702\n",
      "30073: reward: -313.00, mean_100: -441.88, episodes: 68, epsilon: 0.699\n",
      "30337: reward: -263.00, mean_100: -439.29, episodes: 69, epsilon: 0.697\n",
      "30698: reward: -360.00, mean_100: -438.16, episodes: 70, epsilon: 0.693\n",
      "30938: reward: -239.00, mean_100: -435.35, episodes: 71, epsilon: 0.691\n",
      "31198: reward: -259.00, mean_100: -432.90, episodes: 72, epsilon: 0.688\n",
      "31389: reward: -190.00, mean_100: -429.58, episodes: 73, epsilon: 0.686\n",
      "31602: reward: -212.00, mean_100: -426.64, episodes: 74, epsilon: 0.684\n",
      "31882: reward: -279.00, mean_100: -424.67, episodes: 75, epsilon: 0.681\n",
      "32158: reward: -275.00, mean_100: -422.70, episodes: 76, epsilon: 0.678\n",
      "32304: reward: -145.00, mean_100: -419.09, episodes: 77, epsilon: 0.677\n",
      "32593: reward: -288.00, mean_100: -417.41, episodes: 78, epsilon: 0.674\n",
      "32945: reward: -351.00, mean_100: -416.57, episodes: 79, epsilon: 0.671\n",
      "33116: reward: -170.00, mean_100: -413.49, episodes: 80, epsilon: 0.669\n",
      "33294: reward: -177.00, mean_100: -410.57, episodes: 81, epsilon: 0.667\n",
      "33607: reward: -312.00, mean_100: -409.37, episodes: 82, epsilon: 0.664\n",
      "33876: reward: -268.00, mean_100: -407.66, episodes: 83, epsilon: 0.661\n",
      "34186: reward: -309.00, mean_100: -406.49, episodes: 84, epsilon: 0.658\n",
      "34429: reward: -242.00, mean_100: -404.55, episodes: 85, epsilon: 0.656\n",
      "34701: reward: -271.00, mean_100: -403.00, episodes: 86, epsilon: 0.653\n",
      "35063: reward: -361.00, mean_100: -402.52, episodes: 87, epsilon: 0.649\n",
      "35334: reward: -270.00, mean_100: -401.01, episodes: 88, epsilon: 0.647\n",
      "35718: reward: -383.00, mean_100: -400.81, episodes: 89, epsilon: 0.643\n",
      "35873: reward: -154.00, mean_100: -398.07, episodes: 90, epsilon: 0.641\n",
      "36122: reward: -248.00, mean_100: -396.42, episodes: 91, epsilon: 0.639\n",
      "36316: reward: -193.00, mean_100: -394.21, episodes: 92, epsilon: 0.637\n",
      "36587: reward: -270.00, mean_100: -392.87, episodes: 93, epsilon: 0.634\n",
      "36867: reward: -279.00, mean_100: -391.66, episodes: 94, epsilon: 0.631\n",
      "37164: reward: -296.00, mean_100: -390.65, episodes: 95, epsilon: 0.628\n",
      "37381: reward: -216.00, mean_100: -388.83, episodes: 96, epsilon: 0.626\n",
      "37659: reward: -277.00, mean_100: -387.68, episodes: 97, epsilon: 0.623\n",
      "37964: reward: -304.00, mean_100: -386.83, episodes: 98, epsilon: 0.620\n",
      "38199: reward: -234.00, mean_100: -385.28, episodes: 99, epsilon: 0.618\n",
      "38451: reward: -251.00, mean_100: -383.94, episodes: 100, epsilon: 0.615\n",
      "38452: reward: -1.00, mean_100: -378.95, episodes: 101, epsilon: 0.615\n",
      "38660: reward: -207.00, mean_100: -376.02, episodes: 102, epsilon: 0.613\n",
      "38899: reward: -238.00, mean_100: -373.40, episodes: 103, epsilon: 0.611\n",
      "39131: reward: -231.00, mean_100: -370.71, episodes: 104, epsilon: 0.609\n",
      "39405: reward: -273.00, mean_100: -368.44, episodes: 105, epsilon: 0.606\n",
      "39527: reward: -121.00, mean_100: -364.65, episodes: 106, epsilon: 0.605\n",
      "39733: reward: -205.00, mean_100: -361.70, episodes: 107, epsilon: 0.603\n",
      "40014: reward: -280.00, mean_100: -359.50, episodes: 108, epsilon: 0.600\n",
      "40235: reward: -220.00, mean_100: -356.70, episodes: 109, epsilon: 0.598\n",
      "40414: reward: -178.00, mean_100: -353.48, episodes: 110, epsilon: 0.596\n",
      "40633: reward: -218.00, mean_100: -350.66, episodes: 111, epsilon: 0.594\n",
      "40884: reward: -250.00, mean_100: -348.16, episodes: 112, epsilon: 0.591\n",
      "41131: reward: -246.00, mean_100: -345.62, episodes: 113, epsilon: 0.589\n",
      "41319: reward: -187.00, mean_100: -342.49, episodes: 114, epsilon: 0.587\n",
      "41701: reward: -381.00, mean_100: -341.30, episodes: 115, epsilon: 0.583\n",
      "41986: reward: -284.00, mean_100: -339.14, episodes: 116, epsilon: 0.580\n",
      "42270: reward: -283.00, mean_100: -336.97, episodes: 117, epsilon: 0.577\n",
      "42541: reward: -270.00, mean_100: -334.67, episodes: 118, epsilon: 0.575\n",
      "42746: reward: -204.00, mean_100: -331.71, episodes: 119, epsilon: 0.573\n",
      "42973: reward: -226.00, mean_100: -328.97, episodes: 120, epsilon: 0.570\n",
      "43256: reward: -282.00, mean_100: -326.79, episodes: 121, epsilon: 0.567\n",
      "43501: reward: -244.00, mean_100: -324.23, episodes: 122, epsilon: 0.565\n",
      "43787: reward: -285.00, mean_100: -322.08, episodes: 123, epsilon: 0.562\n",
      "44155: reward: -367.00, mean_100: -320.75, episodes: 124, epsilon: 0.558\n",
      "44349: reward: -193.00, mean_100: -317.68, episodes: 125, epsilon: 0.557\n",
      "44574: reward: -224.00, mean_100: -314.92, episodes: 126, epsilon: 0.554\n",
      "44798: reward: -223.00, mean_100: -312.15, episodes: 127, epsilon: 0.552\n",
      "44934: reward: -135.00, mean_100: -308.50, episodes: 128, epsilon: 0.551\n",
      "45147: reward: -212.00, mean_100: -305.62, episodes: 129, epsilon: 0.549\n",
      "45321: reward: -173.00, mean_100: -303.01, episodes: 130, epsilon: 0.547\n",
      "45510: reward: -188.00, mean_100: -299.89, episodes: 131, epsilon: 0.545\n",
      "45746: reward: -235.00, mean_100: -297.24, episodes: 132, epsilon: 0.543\n",
      "45941: reward: -194.00, mean_100: -294.18, episodes: 133, epsilon: 0.541\n",
      "46101: reward: -159.00, mean_100: -290.77, episodes: 134, epsilon: 0.539\n",
      "46330: reward: -228.00, mean_100: -288.05, episodes: 135, epsilon: 0.537\n",
      "46592: reward: -261.00, mean_100: -287.18, episodes: 136, epsilon: 0.534\n",
      "46764: reward: -171.00, mean_100: -283.89, episodes: 137, epsilon: 0.532\n",
      "46968: reward: -203.00, mean_100: -280.92, episodes: 138, epsilon: 0.530\n",
      "47198: reward: -229.00, mean_100: -278.74, episodes: 139, epsilon: 0.528\n",
      "47366: reward: -167.00, mean_100: -275.41, episodes: 140, epsilon: 0.526\n",
      "47559: reward: -192.00, mean_100: -272.61, episodes: 141, epsilon: 0.524\n",
      "47774: reward: -214.00, mean_100: -272.09, episodes: 142, epsilon: 0.522\n",
      "47996: reward: -221.00, mean_100: -269.64, episodes: 143, epsilon: 0.520\n",
      "48162: reward: -165.00, mean_100: -267.04, episodes: 144, epsilon: 0.518\n",
      "48424: reward: -261.00, mean_100: -267.13, episodes: 145, epsilon: 0.516\n",
      "48576: reward: -151.00, mean_100: -265.13, episodes: 146, epsilon: 0.514\n",
      "48765: reward: -188.00, mean_100: -262.01, episodes: 147, epsilon: 0.512\n",
      "49046: reward: -280.00, mean_100: -259.81, episodes: 148, epsilon: 0.510\n",
      "49239: reward: -192.00, mean_100: -256.73, episodes: 149, epsilon: 0.508\n",
      "49463: reward: -223.00, mean_100: -254.32, episodes: 150, epsilon: 0.505\n",
      "49753: reward: -289.00, mean_100: -252.21, episodes: 151, epsilon: 0.502\n",
      "49956: reward: -202.00, mean_100: -249.25, episodes: 152, epsilon: 0.500\n",
      "50151: reward: -194.00, mean_100: -247.08, episodes: 153, epsilon: 0.498\n",
      "50308: reward: -156.00, mean_100: -245.17, episodes: 154, epsilon: 0.497\n",
      "50589: reward: -280.00, mean_100: -245.58, episodes: 155, epsilon: 0.494\n",
      "51089: reward: -500.00, mean_100: -247.38, episodes: 156, epsilon: 0.489\n",
      "51284: reward: -194.00, mean_100: -246.30, episodes: 157, epsilon: 0.487\n",
      "51438: reward: -153.00, mean_100: -245.71, episodes: 158, epsilon: 0.486\n",
      "51630: reward: -191.00, mean_100: -243.74, episodes: 159, epsilon: 0.484\n",
      "51779: reward: -148.00, mean_100: -242.31, episodes: 160, epsilon: 0.482\n",
      "51957: reward: -177.00, mean_100: -241.84, episodes: 161, epsilon: 0.480\n",
      "52114: reward: -156.00, mean_100: -238.40, episodes: 162, epsilon: 0.479\n",
      "52265: reward: -150.00, mean_100: -237.69, episodes: 163, epsilon: 0.477\n",
      "52449: reward: -183.00, mean_100: -237.14, episodes: 164, epsilon: 0.476\n",
      "52690: reward: -240.00, mean_100: -236.34, episodes: 165, epsilon: 0.473\n",
      "52840: reward: -149.00, mean_100: -232.83, episodes: 166, epsilon: 0.472\n",
      "53172: reward: -331.00, mean_100: -233.15, episodes: 167, epsilon: 0.468\n",
      "53324: reward: -151.00, mean_100: -231.53, episodes: 168, epsilon: 0.467\n",
      "53489: reward: -164.00, mean_100: -230.54, episodes: 169, epsilon: 0.465\n",
      "53689: reward: -199.00, mean_100: -228.93, episodes: 170, epsilon: 0.463\n",
      "53890: reward: -200.00, mean_100: -228.54, episodes: 171, epsilon: 0.461\n",
      "54059: reward: -168.00, mean_100: -227.63, episodes: 172, epsilon: 0.459\n",
      "54305: reward: -245.00, mean_100: -228.18, episodes: 173, epsilon: 0.457\n",
      "54664: reward: -358.00, mean_100: -229.64, episodes: 174, epsilon: 0.453\n",
      "54900: reward: -235.00, mean_100: -229.20, episodes: 175, epsilon: 0.451\n",
      "55071: reward: -170.00, mean_100: -228.15, episodes: 176, epsilon: 0.449\n",
      "55397: reward: -325.00, mean_100: -229.95, episodes: 177, epsilon: 0.446\n",
      "55599: reward: -201.00, mean_100: -229.08, episodes: 178, epsilon: 0.444\n",
      "55749: reward: -149.00, mean_100: -227.06, episodes: 179, epsilon: 0.443\n",
      "55965: reward: -215.00, mean_100: -227.51, episodes: 180, epsilon: 0.440\n",
      "56185: reward: -219.00, mean_100: -227.93, episodes: 181, epsilon: 0.438\n",
      "56311: reward: -125.00, mean_100: -226.06, episodes: 182, epsilon: 0.437\n",
      "56480: reward: -168.00, mean_100: -225.06, episodes: 183, epsilon: 0.435\n",
      "56631: reward: -150.00, mean_100: -223.47, episodes: 184, epsilon: 0.434\n",
      "56810: reward: -178.00, mean_100: -222.83, episodes: 185, epsilon: 0.432\n",
      "56965: reward: -154.00, mean_100: -221.66, episodes: 186, epsilon: 0.430\n",
      "57138: reward: -172.00, mean_100: -219.77, episodes: 187, epsilon: 0.429\n",
      "57320: reward: -181.00, mean_100: -218.88, episodes: 188, epsilon: 0.427\n",
      "57482: reward: -161.00, mean_100: -216.66, episodes: 189, epsilon: 0.425\n",
      "57633: reward: -150.00, mean_100: -216.62, episodes: 190, epsilon: 0.424\n",
      "57766: reward: -132.00, mean_100: -215.46, episodes: 191, epsilon: 0.422\n",
      "57957: reward: -190.00, mean_100: -215.43, episodes: 192, epsilon: 0.420\n",
      "58112: reward: -154.00, mean_100: -214.27, episodes: 193, epsilon: 0.419\n",
      "58304: reward: -191.00, mean_100: -213.39, episodes: 194, epsilon: 0.417\n",
      "58489: reward: -184.00, mean_100: -212.27, episodes: 195, epsilon: 0.415\n",
      "58625: reward: -135.00, mean_100: -211.46, episodes: 196, epsilon: 0.414\n",
      "58823: reward: -197.00, mean_100: -210.66, episodes: 197, epsilon: 0.412\n",
      "58928: reward: -104.00, mean_100: -208.66, episodes: 198, epsilon: 0.411\n",
      "59069: reward: -140.00, mean_100: -207.72, episodes: 199, epsilon: 0.409\n",
      "59343: reward: -273.00, mean_100: -207.94, episodes: 200, epsilon: 0.407\n",
      "59344: reward: -1.00, mean_100: -207.94, episodes: 201, epsilon: 0.407\n",
      "59458: reward: -113.00, mean_100: -207.00, episodes: 202, epsilon: 0.405\n",
      "59602: reward: -143.00, mean_100: -206.05, episodes: 203, epsilon: 0.404\n",
      "59713: reward: -110.00, mean_100: -204.84, episodes: 204, epsilon: 0.403\n",
      "59902: reward: -188.00, mean_100: -203.99, episodes: 205, epsilon: 0.401\n",
      "60033: reward: -130.00, mean_100: -204.08, episodes: 206, epsilon: 0.400\n",
      "60153: reward: -119.00, mean_100: -203.22, episodes: 207, epsilon: 0.398\n",
      "60352: reward: -198.00, mean_100: -202.40, episodes: 208, epsilon: 0.396\n",
      "60520: reward: -167.00, mean_100: -201.87, episodes: 209, epsilon: 0.395\n",
      "60648: reward: -127.00, mean_100: -201.36, episodes: 210, epsilon: 0.394\n",
      "60883: reward: -234.00, mean_100: -201.52, episodes: 211, epsilon: 0.391\n",
      "61045: reward: -161.00, mean_100: -200.63, episodes: 212, epsilon: 0.390\n",
      "61211: reward: -165.00, mean_100: -199.82, episodes: 213, epsilon: 0.388\n",
      "61480: reward: -268.00, mean_100: -200.63, episodes: 214, epsilon: 0.385\n",
      "61640: reward: -159.00, mean_100: -198.41, episodes: 215, epsilon: 0.384\n",
      "61819: reward: -178.00, mean_100: -197.35, episodes: 216, epsilon: 0.382\n",
      "62033: reward: -213.00, mean_100: -196.65, episodes: 217, epsilon: 0.380\n",
      "62208: reward: -174.00, mean_100: -195.69, episodes: 218, epsilon: 0.378\n",
      "62347: reward: -138.00, mean_100: -195.03, episodes: 219, epsilon: 0.377\n",
      "62533: reward: -185.00, mean_100: -194.62, episodes: 220, epsilon: 0.375\n",
      "62641: reward: -107.00, mean_100: -192.87, episodes: 221, epsilon: 0.374\n",
      "62860: reward: -218.00, mean_100: -192.61, episodes: 222, epsilon: 0.371\n",
      "63012: reward: -151.00, mean_100: -191.27, episodes: 223, epsilon: 0.370\n",
      "63140: reward: -127.00, mean_100: -188.87, episodes: 224, epsilon: 0.369\n",
      "63251: reward: -110.00, mean_100: -188.04, episodes: 225, epsilon: 0.367\n",
      "63494: reward: -242.00, mean_100: -188.22, episodes: 226, epsilon: 0.365\n",
      "63630: reward: -135.00, mean_100: -187.34, episodes: 227, epsilon: 0.364\n",
      "63771: reward: -140.00, mean_100: -187.39, episodes: 228, epsilon: 0.362\n",
      "63927: reward: -155.00, mean_100: -186.82, episodes: 229, epsilon: 0.361\n",
      "64043: reward: -115.00, mean_100: -186.24, episodes: 230, epsilon: 0.360\n",
      "64189: reward: -145.00, mean_100: -185.81, episodes: 231, epsilon: 0.358\n",
      "64356: reward: -166.00, mean_100: -185.12, episodes: 232, epsilon: 0.356\n",
      "64450: reward: -93.00, mean_100: -184.11, episodes: 233, epsilon: 0.356\n",
      "64563: reward: -112.00, mean_100: -183.64, episodes: 234, epsilon: 0.354\n",
      "64668: reward: -104.00, mean_100: -182.40, episodes: 235, epsilon: 0.353\n",
      "64765: reward: -96.00, mean_100: -180.75, episodes: 236, epsilon: 0.352\n",
      "64856: reward: -90.00, mean_100: -179.94, episodes: 237, epsilon: 0.351\n",
      "64995: reward: -138.00, mean_100: -179.29, episodes: 238, epsilon: 0.350\n",
      "65156: reward: -160.00, mean_100: -178.60, episodes: 239, epsilon: 0.348\n",
      "65286: reward: -129.00, mean_100: -178.22, episodes: 240, epsilon: 0.347\n",
      "65425: reward: -138.00, mean_100: -177.68, episodes: 241, epsilon: 0.346\n",
      "65658: reward: -232.00, mean_100: -177.86, episodes: 242, epsilon: 0.343\n",
      "65785: reward: -126.00, mean_100: -176.91, episodes: 243, epsilon: 0.342\n",
      "66002: reward: -216.00, mean_100: -177.42, episodes: 244, epsilon: 0.340\n",
      "66213: reward: -210.00, mean_100: -176.91, episodes: 245, epsilon: 0.338\n",
      "66341: reward: -127.00, mean_100: -176.67, episodes: 246, epsilon: 0.337\n",
      "66625: reward: -283.00, mean_100: -177.62, episodes: 247, epsilon: 0.334\n",
      "66801: reward: -175.00, mean_100: -176.57, episodes: 248, epsilon: 0.332\n",
      "66931: reward: -129.00, mean_100: -175.94, episodes: 249, epsilon: 0.331\n",
      "67123: reward: -191.00, mean_100: -175.62, episodes: 250, epsilon: 0.329\n",
      "67260: reward: -136.00, mean_100: -174.09, episodes: 251, epsilon: 0.327\n",
      "67352: reward: -91.00, mean_100: -172.98, episodes: 252, epsilon: 0.326\n",
      "67467: reward: -114.00, mean_100: -172.18, episodes: 253, epsilon: 0.325\n",
      "67606: reward: -138.00, mean_100: -172.00, episodes: 254, epsilon: 0.324\n",
      "67718: reward: -111.00, mean_100: -170.31, episodes: 255, epsilon: 0.323\n",
      "67830: reward: -111.00, mean_100: -166.42, episodes: 256, epsilon: 0.322\n",
      "67958: reward: -127.00, mean_100: -165.75, episodes: 257, epsilon: 0.320\n",
      "68104: reward: -145.00, mean_100: -165.67, episodes: 258, epsilon: 0.319\n",
      "68285: reward: -180.00, mean_100: -165.56, episodes: 259, epsilon: 0.317\n",
      "68421: reward: -135.00, mean_100: -165.43, episodes: 260, epsilon: 0.316\n",
      "68546: reward: -124.00, mean_100: -164.90, episodes: 261, epsilon: 0.315\n",
      "68635: reward: -88.00, mean_100: -164.22, episodes: 262, epsilon: 0.314\n",
      "68880: reward: -244.00, mean_100: -165.16, episodes: 263, epsilon: 0.311\n",
      "69014: reward: -133.00, mean_100: -164.66, episodes: 264, epsilon: 0.310\n",
      "69124: reward: -109.00, mean_100: -163.35, episodes: 265, epsilon: 0.309\n",
      "69254: reward: -129.00, mean_100: -163.15, episodes: 266, epsilon: 0.307\n",
      "69379: reward: -124.00, mean_100: -161.08, episodes: 267, epsilon: 0.306\n",
      "69482: reward: -102.00, mean_100: -160.59, episodes: 268, epsilon: 0.305\n",
      "69606: reward: -123.00, mean_100: -160.18, episodes: 269, epsilon: 0.304\n",
      "69695: reward: -88.00, mean_100: -159.07, episodes: 270, epsilon: 0.303\n",
      "69793: reward: -97.00, mean_100: -158.04, episodes: 271, epsilon: 0.302\n",
      "69909: reward: -115.00, mean_100: -157.51, episodes: 272, epsilon: 0.301\n",
      "70024: reward: -114.00, mean_100: -156.20, episodes: 273, epsilon: 0.300\n",
      "70118: reward: -93.00, mean_100: -153.55, episodes: 274, epsilon: 0.299\n",
      "70219: reward: -100.00, mean_100: -152.20, episodes: 275, epsilon: 0.298\n",
      "70338: reward: -118.00, mean_100: -151.68, episodes: 276, epsilon: 0.297\n",
      "70460: reward: -121.00, mean_100: -149.64, episodes: 277, epsilon: 0.295\n",
      "70563: reward: -102.00, mean_100: -148.65, episodes: 278, epsilon: 0.294\n",
      "70658: reward: -94.00, mean_100: -148.10, episodes: 279, epsilon: 0.293\n",
      "70778: reward: -119.00, mean_100: -147.14, episodes: 280, epsilon: 0.292\n",
      "70871: reward: -92.00, mean_100: -145.87, episodes: 281, epsilon: 0.291\n",
      "70970: reward: -98.00, mean_100: -145.60, episodes: 282, epsilon: 0.290\n",
      "71069: reward: -98.00, mean_100: -144.90, episodes: 283, epsilon: 0.289\n",
      "71159: reward: -89.00, mean_100: -144.29, episodes: 284, epsilon: 0.288\n",
      "71255: reward: -95.00, mean_100: -143.46, episodes: 285, epsilon: 0.287\n",
      "71377: reward: -121.00, mean_100: -143.13, episodes: 286, epsilon: 0.286\n",
      "71454: reward: -76.00, mean_100: -142.17, episodes: 287, epsilon: 0.285\n",
      "71558: reward: -103.00, mean_100: -141.39, episodes: 288, epsilon: 0.284\n",
      "71726: reward: -167.00, mean_100: -141.45, episodes: 289, epsilon: 0.283\n",
      "71877: reward: -150.00, mean_100: -141.45, episodes: 290, epsilon: 0.281\n",
      "71991: reward: -113.00, mean_100: -141.26, episodes: 291, epsilon: 0.280\n",
      "72092: reward: -100.00, mean_100: -140.36, episodes: 292, epsilon: 0.279\n",
      "72211: reward: -118.00, mean_100: -140.00, episodes: 293, epsilon: 0.278\n",
      "72339: reward: -127.00, mean_100: -139.36, episodes: 294, epsilon: 0.277\n",
      "72459: reward: -119.00, mean_100: -138.71, episodes: 295, epsilon: 0.275\n",
      "72570: reward: -110.00, mean_100: -138.46, episodes: 296, epsilon: 0.274\n",
      "72661: reward: -90.00, mean_100: -137.39, episodes: 297, epsilon: 0.273\n",
      "72773: reward: -111.00, mean_100: -137.46, episodes: 298, epsilon: 0.272\n",
      "72892: reward: -118.00, mean_100: -137.24, episodes: 299, epsilon: 0.271\n",
      "73028: reward: -135.00, mean_100: -135.86, episodes: 300, epsilon: 0.270\n",
      "73029: reward: -1.00, mean_100: -135.86, episodes: 301, epsilon: 0.270\n",
      "73134: reward: -104.00, mean_100: -135.77, episodes: 302, epsilon: 0.269\n",
      "73244: reward: -109.00, mean_100: -135.43, episodes: 303, epsilon: 0.268\n",
      "73330: reward: -85.00, mean_100: -135.18, episodes: 304, epsilon: 0.267\n",
      "73431: reward: -100.00, mean_100: -134.30, episodes: 305, epsilon: 0.266\n",
      "73531: reward: -99.00, mean_100: -133.99, episodes: 306, epsilon: 0.265\n",
      "73667: reward: -135.00, mean_100: -134.15, episodes: 307, epsilon: 0.263\n",
      "73773: reward: -105.00, mean_100: -133.22, episodes: 308, epsilon: 0.262\n",
      "73875: reward: -101.00, mean_100: -132.56, episodes: 309, epsilon: 0.261\n",
      "73975: reward: -99.00, mean_100: -132.28, episodes: 310, epsilon: 0.260\n",
      "74081: reward: -105.00, mean_100: -130.99, episodes: 311, epsilon: 0.259\n",
      "74169: reward: -87.00, mean_100: -130.25, episodes: 312, epsilon: 0.258\n",
      "74290: reward: -120.00, mean_100: -129.80, episodes: 313, epsilon: 0.257\n",
      "74420: reward: -129.00, mean_100: -128.41, episodes: 314, epsilon: 0.256\n",
      "74540: reward: -119.00, mean_100: -128.01, episodes: 315, epsilon: 0.255\n",
      "74644: reward: -103.00, mean_100: -127.26, episodes: 316, epsilon: 0.254\n",
      "74801: reward: -156.00, mean_100: -126.69, episodes: 317, epsilon: 0.252\n",
      "74982: reward: -180.00, mean_100: -126.75, episodes: 318, epsilon: 0.250\n",
      "75093: reward: -110.00, mean_100: -126.47, episodes: 319, epsilon: 0.249\n",
      "75366: reward: -272.00, mean_100: -127.34, episodes: 320, epsilon: 0.246\n",
      "75586: reward: -219.00, mean_100: -128.46, episodes: 321, epsilon: 0.244\n",
      "75765: reward: -178.00, mean_100: -128.06, episodes: 322, epsilon: 0.242\n",
      "75880: reward: -114.00, mean_100: -127.69, episodes: 323, epsilon: 0.241\n",
      "75994: reward: -113.00, mean_100: -127.55, episodes: 324, epsilon: 0.240\n",
      "76126: reward: -131.00, mean_100: -127.76, episodes: 325, epsilon: 0.239\n",
      "76316: reward: -189.00, mean_100: -127.23, episodes: 326, epsilon: 0.237\n",
      "76426: reward: -109.00, mean_100: -126.97, episodes: 327, epsilon: 0.236\n",
      "76549: reward: -122.00, mean_100: -126.79, episodes: 328, epsilon: 0.235\n",
      "76674: reward: -124.00, mean_100: -126.48, episodes: 329, epsilon: 0.233\n",
      "76771: reward: -96.00, mean_100: -126.29, episodes: 330, epsilon: 0.232\n",
      "76890: reward: -118.00, mean_100: -126.02, episodes: 331, epsilon: 0.231\n",
      "77001: reward: -110.00, mean_100: -125.46, episodes: 332, epsilon: 0.230\n",
      "77093: reward: -91.00, mean_100: -125.44, episodes: 333, epsilon: 0.229\n",
      "77219: reward: -125.00, mean_100: -125.57, episodes: 334, epsilon: 0.228\n",
      "77337: reward: -117.00, mean_100: -125.70, episodes: 335, epsilon: 0.227\n",
      "77418: reward: -80.00, mean_100: -125.54, episodes: 336, epsilon: 0.226\n",
      "77518: reward: -99.00, mean_100: -125.63, episodes: 337, epsilon: 0.225\n",
      "77615: reward: -96.00, mean_100: -125.21, episodes: 338, epsilon: 0.224\n",
      "77712: reward: -96.00, mean_100: -124.57, episodes: 339, epsilon: 0.223\n",
      "77796: reward: -83.00, mean_100: -124.11, episodes: 340, epsilon: 0.222\n",
      "77872: reward: -75.00, mean_100: -123.48, episodes: 341, epsilon: 0.221\n",
      "77982: reward: -109.00, mean_100: -122.25, episodes: 342, epsilon: 0.220\n",
      "78096: reward: -113.00, mean_100: -122.12, episodes: 343, epsilon: 0.219\n",
      "78215: reward: -118.00, mean_100: -121.14, episodes: 344, epsilon: 0.218\n",
      "78293: reward: -77.00, mean_100: -119.81, episodes: 345, epsilon: 0.217\n",
      "78396: reward: -102.00, mean_100: -119.56, episodes: 346, epsilon: 0.216\n",
      "78506: reward: -109.00, mean_100: -117.82, episodes: 347, epsilon: 0.215\n",
      "78627: reward: -120.00, mean_100: -117.27, episodes: 348, epsilon: 0.214\n",
      "78709: reward: -81.00, mean_100: -116.79, episodes: 349, epsilon: 0.213\n",
      "78804: reward: -94.00, mean_100: -115.82, episodes: 350, epsilon: 0.212\n",
      "78911: reward: -106.00, mean_100: -115.52, episodes: 351, epsilon: 0.211\n",
      "79039: reward: -127.00, mean_100: -115.88, episodes: 352, epsilon: 0.210\n",
      "79145: reward: -105.00, mean_100: -115.79, episodes: 353, epsilon: 0.209\n",
      "79240: reward: -94.00, mean_100: -115.35, episodes: 354, epsilon: 0.208\n",
      "79339: reward: -98.00, mean_100: -115.22, episodes: 355, epsilon: 0.207\n",
      "79456: reward: -116.00, mean_100: -115.27, episodes: 356, epsilon: 0.205\n",
      "79571: reward: -114.00, mean_100: -115.14, episodes: 357, epsilon: 0.204\n",
      "79670: reward: -98.00, mean_100: -114.67, episodes: 358, epsilon: 0.203\n",
      "79756: reward: -85.00, mean_100: -113.72, episodes: 359, epsilon: 0.202\n",
      "79840: reward: -83.00, mean_100: -113.20, episodes: 360, epsilon: 0.202\n",
      "79959: reward: -118.00, mean_100: -113.14, episodes: 361, epsilon: 0.200\n",
      "80051: reward: -91.00, mean_100: -113.17, episodes: 362, epsilon: 0.199\n",
      "80163: reward: -111.00, mean_100: -111.84, episodes: 363, epsilon: 0.198\n",
      "80283: reward: -119.00, mean_100: -111.70, episodes: 364, epsilon: 0.197\n",
      "80422: reward: -138.00, mean_100: -111.99, episodes: 365, epsilon: 0.196\n",
      "80519: reward: -96.00, mean_100: -111.66, episodes: 366, epsilon: 0.195\n",
      "80600: reward: -80.00, mean_100: -111.22, episodes: 367, epsilon: 0.194\n",
      "80696: reward: -95.00, mean_100: -111.15, episodes: 368, epsilon: 0.193\n",
      "80759: reward: -62.00, mean_100: -110.54, episodes: 369, epsilon: 0.192\n",
      "80889: reward: -129.00, mean_100: -110.95, episodes: 370, epsilon: 0.191\n",
      "80986: reward: -96.00, mean_100: -110.94, episodes: 371, epsilon: 0.190\n",
      "81064: reward: -77.00, mean_100: -110.56, episodes: 372, epsilon: 0.189\n",
      "81188: reward: -123.00, mean_100: -110.65, episodes: 373, epsilon: 0.188\n",
      "81303: reward: -114.00, mean_100: -110.86, episodes: 374, epsilon: 0.187\n",
      "81452: reward: -148.00, mean_100: -111.34, episodes: 375, epsilon: 0.185\n",
      "81553: reward: -100.00, mean_100: -111.16, episodes: 376, epsilon: 0.184\n",
      "81677: reward: -123.00, mean_100: -111.18, episodes: 377, epsilon: 0.183\n",
      "81795: reward: -117.00, mean_100: -111.33, episodes: 378, epsilon: 0.182\n",
      "81892: reward: -96.00, mean_100: -111.35, episodes: 379, epsilon: 0.181\n",
      "81988: reward: -95.00, mean_100: -111.11, episodes: 380, epsilon: 0.180\n",
      "82142: reward: -153.00, mean_100: -111.72, episodes: 381, epsilon: 0.179\n",
      "82229: reward: -86.00, mean_100: -111.60, episodes: 382, epsilon: 0.178\n",
      "82325: reward: -95.00, mean_100: -111.57, episodes: 383, epsilon: 0.177\n",
      "82533: reward: -207.00, mean_100: -112.75, episodes: 384, epsilon: 0.175\n",
      "82640: reward: -106.00, mean_100: -112.86, episodes: 385, epsilon: 0.174\n",
      "82737: reward: -96.00, mean_100: -112.61, episodes: 386, epsilon: 0.173\n",
      "82941: reward: -203.00, mean_100: -113.88, episodes: 387, epsilon: 0.171\n",
      "83075: reward: -133.00, mean_100: -114.18, episodes: 388, epsilon: 0.169\n",
      "83146: reward: -70.00, mean_100: -113.21, episodes: 389, epsilon: 0.169\n",
      "83231: reward: -84.00, mean_100: -112.55, episodes: 390, epsilon: 0.168\n",
      "83359: reward: -127.00, mean_100: -112.69, episodes: 391, epsilon: 0.166\n",
      "83454: reward: -94.00, mean_100: -112.63, episodes: 392, epsilon: 0.165\n",
      "83597: reward: -142.00, mean_100: -112.87, episodes: 393, epsilon: 0.164\n",
      "83687: reward: -89.00, mean_100: -112.49, episodes: 394, epsilon: 0.163\n",
      "83794: reward: -106.00, mean_100: -112.36, episodes: 395, epsilon: 0.162\n",
      "83877: reward: -82.00, mean_100: -112.08, episodes: 396, epsilon: 0.161\n",
      "83970: reward: -92.00, mean_100: -112.10, episodes: 397, epsilon: 0.160\n",
      "84066: reward: -95.00, mean_100: -111.94, episodes: 398, epsilon: 0.159\n",
      "84171: reward: -104.00, mean_100: -111.80, episodes: 399, epsilon: 0.158\n",
      "84294: reward: -122.00, mean_100: -111.67, episodes: 400, epsilon: 0.157\n",
      "84295: reward: 0.00, mean_100: -111.66, episodes: 401, epsilon: 0.157\n",
      "84393: reward: -97.00, mean_100: -111.59, episodes: 402, epsilon: 0.156\n",
      "84456: reward: -62.00, mean_100: -111.12, episodes: 403, epsilon: 0.155\n",
      "84540: reward: -83.00, mean_100: -111.10, episodes: 404, epsilon: 0.155\n",
      "84637: reward: -96.00, mean_100: -111.06, episodes: 405, epsilon: 0.154\n",
      "84720: reward: -82.00, mean_100: -110.89, episodes: 406, epsilon: 0.153\n",
      "84827: reward: -106.00, mean_100: -110.60, episodes: 407, epsilon: 0.152\n",
      "84904: reward: -76.00, mean_100: -110.31, episodes: 408, epsilon: 0.151\n",
      "84990: reward: -85.00, mean_100: -110.15, episodes: 409, epsilon: 0.150\n",
      "85061: reward: -70.00, mean_100: -109.86, episodes: 410, epsilon: 0.149\n",
      "85160: reward: -98.00, mean_100: -109.79, episodes: 411, epsilon: 0.148\n",
      "85251: reward: -90.00, mean_100: -109.82, episodes: 412, epsilon: 0.147\n",
      "85333: reward: -81.00, mean_100: -109.43, episodes: 413, epsilon: 0.147\n",
      "85453: reward: -119.00, mean_100: -109.33, episodes: 414, epsilon: 0.145\n",
      "85549: reward: -95.00, mean_100: -109.09, episodes: 415, epsilon: 0.145\n",
      "85676: reward: -126.00, mean_100: -109.32, episodes: 416, epsilon: 0.143\n",
      "85762: reward: -85.00, mean_100: -108.61, episodes: 417, epsilon: 0.142\n",
      "85845: reward: -82.00, mean_100: -107.63, episodes: 418, epsilon: 0.142\n",
      "85929: reward: -83.00, mean_100: -107.36, episodes: 419, epsilon: 0.141\n",
      "86011: reward: -81.00, mean_100: -105.45, episodes: 420, epsilon: 0.140\n",
      "86094: reward: -82.00, mean_100: -104.08, episodes: 421, epsilon: 0.139\n",
      "86186: reward: -91.00, mean_100: -103.21, episodes: 422, epsilon: 0.138\n",
      "86313: reward: -126.00, mean_100: -103.33, episodes: 423, epsilon: 0.137\n",
      "86393: reward: -79.00, mean_100: -102.99, episodes: 424, epsilon: 0.136\n",
      "86469: reward: -75.00, mean_100: -102.43, episodes: 425, epsilon: 0.135\n",
      "86567: reward: -97.00, mean_100: -101.51, episodes: 426, epsilon: 0.134\n",
      "86676: reward: -108.00, mean_100: -101.50, episodes: 427, epsilon: 0.133\n",
      "86780: reward: -103.00, mean_100: -101.31, episodes: 428, epsilon: 0.132\n",
      "86859: reward: -78.00, mean_100: -100.85, episodes: 429, epsilon: 0.131\n",
      "86952: reward: -92.00, mean_100: -100.81, episodes: 430, epsilon: 0.130\n",
      "87063: reward: -110.00, mean_100: -100.73, episodes: 431, epsilon: 0.129\n",
      "87161: reward: -97.00, mean_100: -100.60, episodes: 432, epsilon: 0.128\n",
      "87267: reward: -105.00, mean_100: -100.74, episodes: 433, epsilon: 0.127\n",
      "87404: reward: -136.00, mean_100: -100.85, episodes: 434, epsilon: 0.126\n",
      "87531: reward: -126.00, mean_100: -100.94, episodes: 435, epsilon: 0.125\n",
      "87626: reward: -94.00, mean_100: -101.08, episodes: 436, epsilon: 0.124\n",
      "87738: reward: -111.00, mean_100: -101.20, episodes: 437, epsilon: 0.123\n",
      "87820: reward: -81.00, mean_100: -101.05, episodes: 438, epsilon: 0.122\n",
      "87936: reward: -115.00, mean_100: -101.24, episodes: 439, epsilon: 0.121\n",
      "88055: reward: -118.00, mean_100: -101.59, episodes: 440, epsilon: 0.119\n",
      "88160: reward: -104.00, mean_100: -101.88, episodes: 441, epsilon: 0.118\n",
      "88297: reward: -136.00, mean_100: -102.15, episodes: 442, epsilon: 0.117\n",
      "88426: reward: -128.00, mean_100: -102.30, episodes: 443, epsilon: 0.116\n",
      "88536: reward: -109.00, mean_100: -102.21, episodes: 444, epsilon: 0.115\n",
      "88655: reward: -118.00, mean_100: -102.62, episodes: 445, epsilon: 0.113\n",
      "88854: reward: -198.00, mean_100: -103.58, episodes: 446, epsilon: 0.111\n",
      "89067: reward: -212.00, mean_100: -104.61, episodes: 447, epsilon: 0.109\n",
      "89188: reward: -120.00, mean_100: -104.61, episodes: 448, epsilon: 0.108\n",
      "89394: reward: -205.00, mean_100: -105.85, episodes: 449, epsilon: 0.106\n",
      "89552: reward: -157.00, mean_100: -106.48, episodes: 450, epsilon: 0.104\n",
      "89646: reward: -93.00, mean_100: -106.35, episodes: 451, epsilon: 0.104\n",
      "89730: reward: -83.00, mean_100: -105.91, episodes: 452, epsilon: 0.103\n",
      "89826: reward: -95.00, mean_100: -105.81, episodes: 453, epsilon: 0.102\n",
      "89926: reward: -99.00, mean_100: -105.86, episodes: 454, epsilon: 0.101\n",
      "90061: reward: -134.00, mean_100: -106.22, episodes: 455, epsilon: 0.099\n",
      "90223: reward: -161.00, mean_100: -106.67, episodes: 456, epsilon: 0.098\n",
      "90344: reward: -120.00, mean_100: -106.73, episodes: 457, epsilon: 0.097\n",
      "90456: reward: -111.00, mean_100: -106.86, episodes: 458, epsilon: 0.095\n",
      "90541: reward: -84.00, mean_100: -106.85, episodes: 459, epsilon: 0.095\n",
      "90644: reward: -102.00, mean_100: -107.04, episodes: 460, epsilon: 0.094\n",
      "90726: reward: -81.00, mean_100: -106.67, episodes: 461, epsilon: 0.093\n",
      "90799: reward: -72.00, mean_100: -106.48, episodes: 462, epsilon: 0.092\n",
      "90923: reward: -123.00, mean_100: -106.60, episodes: 463, epsilon: 0.091\n",
      "91031: reward: -107.00, mean_100: -106.48, episodes: 464, epsilon: 0.090\n",
      "91130: reward: -98.00, mean_100: -106.08, episodes: 465, epsilon: 0.089\n",
      "91214: reward: -83.00, mean_100: -105.95, episodes: 466, epsilon: 0.088\n",
      "91306: reward: -91.00, mean_100: -106.06, episodes: 467, epsilon: 0.087\n",
      "91433: reward: -126.00, mean_100: -106.37, episodes: 468, epsilon: 0.086\n",
      "91528: reward: -94.00, mean_100: -106.69, episodes: 469, epsilon: 0.085\n",
      "91616: reward: -87.00, mean_100: -106.27, episodes: 470, epsilon: 0.084\n",
      "91710: reward: -93.00, mean_100: -106.24, episodes: 471, epsilon: 0.083\n",
      "91784: reward: -73.00, mean_100: -106.20, episodes: 472, epsilon: 0.082\n",
      "91876: reward: -91.00, mean_100: -105.88, episodes: 473, epsilon: 0.081\n",
      "91948: reward: -71.00, mean_100: -105.45, episodes: 474, epsilon: 0.081\n",
      "92042: reward: -93.00, mean_100: -104.90, episodes: 475, epsilon: 0.080\n",
      "92120: reward: -77.00, mean_100: -104.67, episodes: 476, epsilon: 0.079\n",
      "92215: reward: -94.00, mean_100: -104.38, episodes: 477, epsilon: 0.078\n",
      "92310: reward: -94.00, mean_100: -104.15, episodes: 478, epsilon: 0.077\n",
      "92423: reward: -112.00, mean_100: -104.31, episodes: 479, epsilon: 0.076\n",
      "92492: reward: -68.00, mean_100: -104.04, episodes: 480, epsilon: 0.075\n",
      "92577: reward: -84.00, mean_100: -103.35, episodes: 481, epsilon: 0.074\n",
      "92684: reward: -106.00, mean_100: -103.55, episodes: 482, epsilon: 0.073\n",
      "92758: reward: -73.00, mean_100: -103.33, episodes: 483, epsilon: 0.072\n",
      "92843: reward: -84.00, mean_100: -102.10, episodes: 484, epsilon: 0.072\n",
      "92946: reward: -102.00, mean_100: -102.06, episodes: 485, epsilon: 0.071\n",
      "93036: reward: -89.00, mean_100: -101.99, episodes: 486, epsilon: 0.070\n",
      "93129: reward: -92.00, mean_100: -100.88, episodes: 487, epsilon: 0.069\n",
      "93220: reward: -90.00, mean_100: -100.45, episodes: 488, epsilon: 0.068\n",
      "93294: reward: -73.00, mean_100: -100.48, episodes: 489, epsilon: 0.067\n",
      "93381: reward: -86.00, mean_100: -100.50, episodes: 490, epsilon: 0.066\n",
      "93498: reward: -116.00, mean_100: -100.39, episodes: 491, epsilon: 0.065\n",
      "93596: reward: -97.00, mean_100: -100.42, episodes: 492, epsilon: 0.064\n",
      "93735: reward: -138.00, mean_100: -100.38, episodes: 493, epsilon: 0.063\n",
      "93827: reward: -91.00, mean_100: -100.40, episodes: 494, epsilon: 0.062\n",
      "93927: reward: -99.00, mean_100: -100.33, episodes: 495, epsilon: 0.061\n",
      "94016: reward: -88.00, mean_100: -100.39, episodes: 496, epsilon: 0.060\n",
      "94110: reward: -93.00, mean_100: -100.40, episodes: 497, epsilon: 0.059\n",
      "94207: reward: -96.00, mean_100: -100.41, episodes: 498, epsilon: 0.058\n",
      "94284: reward: -76.00, mean_100: -100.13, episodes: 499, epsilon: 0.057\n",
      "94397: reward: -112.00, mean_100: -100.03, episodes: 500, epsilon: 0.056\n",
      "94398: reward: 0.00, mean_100: -100.03, episodes: 501, epsilon: 0.056\n",
      "94464: reward: -65.00, mean_100: -99.71, episodes: 502, epsilon: 0.055\n",
      "94547: reward: -82.00, mean_100: -99.91, episodes: 503, epsilon: 0.055\n",
      "94631: reward: -83.00, mean_100: -99.91, episodes: 504, epsilon: 0.054\n",
      "94725: reward: -93.00, mean_100: -99.88, episodes: 505, epsilon: 0.053\n",
      "94872: reward: -146.00, mean_100: -100.52, episodes: 506, epsilon: 0.051\n",
      "94955: reward: -82.00, mean_100: -100.28, episodes: 507, epsilon: 0.050\n",
      "95040: reward: -84.00, mean_100: -100.36, episodes: 508, epsilon: 0.050\n",
      "95111: reward: -70.00, mean_100: -100.21, episodes: 509, epsilon: 0.049\n",
      "95201: reward: -89.00, mean_100: -100.40, episodes: 510, epsilon: 0.048\n",
      "95314: reward: -112.00, mean_100: -100.54, episodes: 511, epsilon: 0.047\n",
      "95420: reward: -105.00, mean_100: -100.69, episodes: 512, epsilon: 0.046\n",
      "95498: reward: -77.00, mean_100: -100.65, episodes: 513, epsilon: 0.045\n",
      "95586: reward: -87.00, mean_100: -100.33, episodes: 514, epsilon: 0.044\n",
      "95716: reward: -129.00, mean_100: -100.67, episodes: 515, epsilon: 0.043\n",
      "95834: reward: -117.00, mean_100: -100.58, episodes: 516, epsilon: 0.042\n",
      "95908: reward: -73.00, mean_100: -100.46, episodes: 517, epsilon: 0.041\n",
      "95981: reward: -72.00, mean_100: -100.36, episodes: 518, epsilon: 0.040\n",
      "96064: reward: -82.00, mean_100: -100.35, episodes: 519, epsilon: 0.039\n",
      "96133: reward: -68.00, mean_100: -100.22, episodes: 520, epsilon: 0.039\n",
      "96228: reward: -94.00, mean_100: -100.34, episodes: 521, epsilon: 0.038\n",
      "96311: reward: -82.00, mean_100: -100.25, episodes: 522, epsilon: 0.037\n",
      "96384: reward: -72.00, mean_100: -99.71, episodes: 523, epsilon: 0.036\n",
      "96465: reward: -80.00, mean_100: -99.72, episodes: 524, epsilon: 0.035\n",
      "96535: reward: -69.00, mean_100: -99.66, episodes: 525, epsilon: 0.035\n",
      "96636: reward: -100.00, mean_100: -99.69, episodes: 526, epsilon: 0.034\n",
      "96714: reward: -77.00, mean_100: -99.38, episodes: 527, epsilon: 0.033\n",
      "96786: reward: -71.00, mean_100: -99.06, episodes: 528, epsilon: 0.032\n",
      "96867: reward: -80.00, mean_100: -99.08, episodes: 529, epsilon: 0.031\n",
      "96989: reward: -121.00, mean_100: -99.37, episodes: 530, epsilon: 0.030\n",
      "97122: reward: -132.00, mean_100: -99.59, episodes: 531, epsilon: 0.029\n",
      "97209: reward: -86.00, mean_100: -99.48, episodes: 532, epsilon: 0.028\n",
      "97299: reward: -89.00, mean_100: -99.32, episodes: 533, epsilon: 0.027\n",
      "97395: reward: -95.00, mean_100: -98.91, episodes: 534, epsilon: 0.026\n",
      "97490: reward: -94.00, mean_100: -98.59, episodes: 535, epsilon: 0.025\n",
      "97598: reward: -107.00, mean_100: -98.72, episodes: 536, epsilon: 0.024\n",
      "97684: reward: -85.00, mean_100: -98.46, episodes: 537, epsilon: 0.023\n",
      "97793: reward: -108.00, mean_100: -98.73, episodes: 538, epsilon: 0.022\n",
      "98007: reward: -213.00, mean_100: -99.71, episodes: 539, epsilon: 0.020\n",
      "98190: reward: -182.00, mean_100: -100.35, episodes: 540, epsilon: 0.018\n",
      "98262: reward: -71.00, mean_100: -100.02, episodes: 541, epsilon: 0.017\n",
      "98456: reward: -193.00, mean_100: -100.59, episodes: 542, epsilon: 0.015\n",
      "98550: reward: -93.00, mean_100: -100.24, episodes: 543, epsilon: 0.014\n",
      "98622: reward: -71.00, mean_100: -99.86, episodes: 544, epsilon: 0.014\n",
      "98699: reward: -76.00, mean_100: -99.44, episodes: 545, epsilon: 0.013\n",
      "98771: reward: -71.00, mean_100: -98.17, episodes: 546, epsilon: 0.012\n",
      "98843: reward: -71.00, mean_100: -96.76, episodes: 547, epsilon: 0.012\n",
      "98932: reward: -88.00, mean_100: -96.44, episodes: 548, epsilon: 0.011\n",
      "99028: reward: -95.00, mean_100: -95.34, episodes: 549, epsilon: 0.010\n",
      "99101: reward: -72.00, mean_100: -94.49, episodes: 550, epsilon: 0.010\n",
      "99178: reward: -76.00, mean_100: -94.32, episodes: 551, epsilon: 0.010\n",
      "99290: reward: -111.00, mean_100: -94.60, episodes: 552, epsilon: 0.010\n",
      "99353: reward: -62.00, mean_100: -94.27, episodes: 553, epsilon: 0.010\n",
      "99444: reward: -90.00, mean_100: -94.18, episodes: 554, epsilon: 0.010\n",
      "99529: reward: -84.00, mean_100: -93.68, episodes: 555, epsilon: 0.010\n",
      "99621: reward: -91.00, mean_100: -92.98, episodes: 556, epsilon: 0.010\n",
      "99713: reward: -91.00, mean_100: -92.69, episodes: 557, epsilon: 0.010\n",
      "100213: reward: -500.00, mean_100: -96.58, episodes: 558, epsilon: 0.010\n",
      "100307: reward: -93.00, mean_100: -96.67, episodes: 559, epsilon: 0.010\n",
      "100428: reward: -120.00, mean_100: -96.85, episodes: 560, epsilon: 0.010\n",
      "100515: reward: -86.00, mean_100: -96.90, episodes: 561, epsilon: 0.010\n",
      "100595: reward: -79.00, mean_100: -96.97, episodes: 562, epsilon: 0.010\n",
      "100673: reward: -77.00, mean_100: -96.51, episodes: 563, epsilon: 0.010\n",
      "100751: reward: -77.00, mean_100: -96.21, episodes: 564, epsilon: 0.010\n",
      "100855: reward: -103.00, mean_100: -96.26, episodes: 565, epsilon: 0.010\n",
      "100932: reward: -76.00, mean_100: -96.19, episodes: 566, epsilon: 0.010\n",
      "101010: reward: -77.00, mean_100: -96.05, episodes: 567, epsilon: 0.010\n",
      "101088: reward: -77.00, mean_100: -95.56, episodes: 568, epsilon: 0.010\n",
      "101199: reward: -110.00, mean_100: -95.72, episodes: 569, epsilon: 0.010\n",
      "101290: reward: -90.00, mean_100: -95.75, episodes: 570, epsilon: 0.010\n",
      "101537: reward: -246.00, mean_100: -97.28, episodes: 571, epsilon: 0.010\n",
      "101779: reward: -241.00, mean_100: -98.96, episodes: 572, epsilon: 0.010\n",
      "101858: reward: -78.00, mean_100: -98.83, episodes: 573, epsilon: 0.010\n",
      "101946: reward: -87.00, mean_100: -98.99, episodes: 574, epsilon: 0.010\n",
      "102034: reward: -87.00, mean_100: -98.93, episodes: 575, epsilon: 0.010\n",
      "102164: reward: -129.00, mean_100: -99.45, episodes: 576, epsilon: 0.010\n",
      "102664: reward: -500.00, mean_100: -103.51, episodes: 577, epsilon: 0.010\n",
      "102879: reward: -214.00, mean_100: -104.71, episodes: 578, epsilon: 0.010\n",
      "102995: reward: -115.00, mean_100: -104.74, episodes: 579, epsilon: 0.010\n",
      "103089: reward: -93.00, mean_100: -104.99, episodes: 580, epsilon: 0.010\n",
      "103589: reward: -500.00, mean_100: -109.15, episodes: 581, epsilon: 0.010\n",
      "103799: reward: -209.00, mean_100: -110.18, episodes: 582, epsilon: 0.010\n",
      "103899: reward: -99.00, mean_100: -110.44, episodes: 583, epsilon: 0.010\n",
      "104399: reward: -500.00, mean_100: -114.60, episodes: 584, epsilon: 0.010\n",
      "104899: reward: -500.00, mean_100: -118.58, episodes: 585, epsilon: 0.010\n",
      "105117: reward: -217.00, mean_100: -119.86, episodes: 586, epsilon: 0.010\n",
      "105206: reward: -88.00, mean_100: -119.82, episodes: 587, epsilon: 0.010\n",
      "105292: reward: -85.00, mean_100: -119.77, episodes: 588, epsilon: 0.010\n",
      "105378: reward: -85.00, mean_100: -119.89, episodes: 589, epsilon: 0.010\n",
      "105474: reward: -95.00, mean_100: -119.98, episodes: 590, epsilon: 0.010\n",
      "105551: reward: -76.00, mean_100: -119.58, episodes: 591, epsilon: 0.010\n",
      "105630: reward: -78.00, mean_100: -119.39, episodes: 592, epsilon: 0.010\n",
      "105716: reward: -85.00, mean_100: -118.86, episodes: 593, epsilon: 0.010\n",
      "105793: reward: -76.00, mean_100: -118.71, episodes: 594, epsilon: 0.010\n",
      "105871: reward: -77.00, mean_100: -118.49, episodes: 595, epsilon: 0.010\n",
      "105948: reward: -76.00, mean_100: -118.37, episodes: 596, epsilon: 0.010\n",
      "106039: reward: -90.00, mean_100: -118.34, episodes: 597, epsilon: 0.010\n",
      "106123: reward: -83.00, mean_100: -118.21, episodes: 598, epsilon: 0.010\n",
      "106198: reward: -74.00, mean_100: -118.19, episodes: 599, epsilon: 0.010\n",
      "106268: reward: -69.00, mean_100: -117.76, episodes: 600, epsilon: 0.010\n",
      "106269: reward: 0.00, mean_100: -117.76, episodes: 601, epsilon: 0.010\n",
      "106377: reward: -107.00, mean_100: -118.18, episodes: 602, epsilon: 0.010\n",
      "106452: reward: -74.00, mean_100: -118.10, episodes: 603, epsilon: 0.010\n",
      "106539: reward: -86.00, mean_100: -118.13, episodes: 604, epsilon: 0.010\n",
      "106634: reward: -94.00, mean_100: -118.14, episodes: 605, epsilon: 0.010\n",
      "106716: reward: -81.00, mean_100: -117.49, episodes: 606, epsilon: 0.010\n",
      "106787: reward: -70.00, mean_100: -117.37, episodes: 607, epsilon: 0.010\n",
      "106933: reward: -145.00, mean_100: -117.98, episodes: 608, epsilon: 0.010\n",
      "107036: reward: -102.00, mean_100: -118.30, episodes: 609, epsilon: 0.010\n",
      "107330: reward: -293.00, mean_100: -120.34, episodes: 610, epsilon: 0.010\n",
      "107458: reward: -127.00, mean_100: -120.49, episodes: 611, epsilon: 0.010\n",
      "107732: reward: -273.00, mean_100: -122.17, episodes: 612, epsilon: 0.010\n",
      "107860: reward: -127.00, mean_100: -122.67, episodes: 613, epsilon: 0.010\n",
      "108360: reward: -500.00, mean_100: -126.80, episodes: 614, epsilon: 0.010\n",
      "108860: reward: -500.00, mean_100: -130.51, episodes: 615, epsilon: 0.010\n",
      "109360: reward: -500.00, mean_100: -134.34, episodes: 616, epsilon: 0.010\n",
      "109860: reward: -500.00, mean_100: -138.61, episodes: 617, epsilon: 0.010\n",
      "110083: reward: -222.00, mean_100: -140.11, episodes: 618, epsilon: 0.010\n",
      "110583: reward: -500.00, mean_100: -144.29, episodes: 619, epsilon: 0.010\n",
      "110838: reward: -254.00, mean_100: -146.15, episodes: 620, epsilon: 0.010\n",
      "111003: reward: -164.00, mean_100: -146.85, episodes: 621, epsilon: 0.010\n",
      "111136: reward: -132.00, mean_100: -147.35, episodes: 622, epsilon: 0.010\n",
      "111201: reward: -64.00, mean_100: -147.27, episodes: 623, epsilon: 0.010\n",
      "111285: reward: -83.00, mean_100: -147.30, episodes: 624, epsilon: 0.010\n",
      "111402: reward: -116.00, mean_100: -147.77, episodes: 625, epsilon: 0.010\n",
      "111515: reward: -112.00, mean_100: -147.89, episodes: 626, epsilon: 0.010\n",
      "111580: reward: -64.00, mean_100: -147.76, episodes: 627, epsilon: 0.010\n",
      "111702: reward: -121.00, mean_100: -148.26, episodes: 628, epsilon: 0.010\n",
      "111775: reward: -72.00, mean_100: -148.18, episodes: 629, epsilon: 0.010\n",
      "111865: reward: -89.00, mean_100: -147.86, episodes: 630, epsilon: 0.010\n",
      "111954: reward: -88.00, mean_100: -147.42, episodes: 631, epsilon: 0.010\n",
      "112078: reward: -123.00, mean_100: -147.79, episodes: 632, epsilon: 0.010\n",
      "112175: reward: -96.00, mean_100: -147.86, episodes: 633, epsilon: 0.010\n",
      "112262: reward: -86.00, mean_100: -147.77, episodes: 634, epsilon: 0.010\n",
      "112348: reward: -85.00, mean_100: -147.68, episodes: 635, epsilon: 0.010\n",
      "112424: reward: -75.00, mean_100: -147.36, episodes: 636, epsilon: 0.010\n",
      "112538: reward: -113.00, mean_100: -147.64, episodes: 637, epsilon: 0.010\n",
      "112599: reward: -60.00, mean_100: -147.16, episodes: 638, epsilon: 0.010\n",
      "113099: reward: -500.00, mean_100: -150.03, episodes: 639, epsilon: 0.010\n",
      "113191: reward: -91.00, mean_100: -149.12, episodes: 640, epsilon: 0.010\n",
      "113269: reward: -77.00, mean_100: -149.18, episodes: 641, epsilon: 0.010\n",
      "113361: reward: -91.00, mean_100: -148.16, episodes: 642, epsilon: 0.010\n",
      "113425: reward: -63.00, mean_100: -147.86, episodes: 643, epsilon: 0.010\n",
      "113502: reward: -76.00, mean_100: -147.91, episodes: 644, epsilon: 0.010\n",
      "113592: reward: -89.00, mean_100: -148.04, episodes: 645, epsilon: 0.010\n",
      "113679: reward: -86.00, mean_100: -148.19, episodes: 646, epsilon: 0.010\n",
      "113780: reward: -100.00, mean_100: -148.48, episodes: 647, epsilon: 0.010\n",
      "113857: reward: -76.00, mean_100: -148.36, episodes: 648, epsilon: 0.010\n",
      "113956: reward: -98.00, mean_100: -148.39, episodes: 649, epsilon: 0.010\n",
      "114068: reward: -111.00, mean_100: -148.78, episodes: 650, epsilon: 0.010\n",
      "114156: reward: -87.00, mean_100: -148.89, episodes: 651, epsilon: 0.010\n",
      "114656: reward: -500.00, mean_100: -152.78, episodes: 652, epsilon: 0.010\n",
      "115156: reward: -500.00, mean_100: -157.16, episodes: 653, epsilon: 0.010\n",
      "115656: reward: -500.00, mean_100: -161.26, episodes: 654, epsilon: 0.010\n",
      "116156: reward: -500.00, mean_100: -165.42, episodes: 655, epsilon: 0.010\n",
      "116583: reward: -426.00, mean_100: -168.77, episodes: 656, epsilon: 0.010\n",
      "117083: reward: -500.00, mean_100: -172.86, episodes: 657, epsilon: 0.010\n",
      "117583: reward: -500.00, mean_100: -172.86, episodes: 658, epsilon: 0.010\n",
      "118070: reward: -486.00, mean_100: -176.79, episodes: 659, epsilon: 0.010\n",
      "118500: reward: -429.00, mean_100: -179.88, episodes: 660, epsilon: 0.010\n",
      "118575: reward: -74.00, mean_100: -179.76, episodes: 661, epsilon: 0.010\n",
      "118653: reward: -77.00, mean_100: -179.74, episodes: 662, epsilon: 0.010\n",
      "118801: reward: -147.00, mean_100: -180.44, episodes: 663, epsilon: 0.010\n",
      "118964: reward: -162.00, mean_100: -181.29, episodes: 664, epsilon: 0.010\n",
      "119057: reward: -92.00, mean_100: -181.18, episodes: 665, epsilon: 0.010\n",
      "119136: reward: -78.00, mean_100: -181.20, episodes: 666, epsilon: 0.010\n",
      "119211: reward: -74.00, mean_100: -181.17, episodes: 667, epsilon: 0.010\n",
      "119298: reward: -86.00, mean_100: -181.26, episodes: 668, epsilon: 0.010\n",
      "119370: reward: -71.00, mean_100: -180.87, episodes: 669, epsilon: 0.010\n",
      "119466: reward: -95.00, mean_100: -180.92, episodes: 670, epsilon: 0.010\n",
      "119563: reward: -96.00, mean_100: -179.42, episodes: 671, epsilon: 0.010\n",
      "119664: reward: -100.00, mean_100: -178.01, episodes: 672, epsilon: 0.010\n",
      "119740: reward: -75.00, mean_100: -177.98, episodes: 673, epsilon: 0.010\n",
      "119836: reward: -95.00, mean_100: -178.06, episodes: 674, epsilon: 0.010\n",
      "119912: reward: -75.00, mean_100: -177.94, episodes: 675, epsilon: 0.010\n",
      "120001: reward: -88.00, mean_100: -177.53, episodes: 676, epsilon: 0.010\n",
      "120089: reward: -87.00, mean_100: -173.40, episodes: 677, epsilon: 0.010\n",
      "120184: reward: -94.00, mean_100: -172.20, episodes: 678, epsilon: 0.010\n",
      "120271: reward: -86.00, mean_100: -171.91, episodes: 679, epsilon: 0.010\n",
      "120369: reward: -97.00, mean_100: -171.95, episodes: 680, epsilon: 0.010\n",
      "120664: reward: -294.00, mean_100: -169.89, episodes: 681, epsilon: 0.010\n",
      "120862: reward: -197.00, mean_100: -169.77, episodes: 682, epsilon: 0.010\n",
      "120968: reward: -105.00, mean_100: -169.83, episodes: 683, epsilon: 0.010\n",
      "121121: reward: -152.00, mean_100: -166.35, episodes: 684, epsilon: 0.010\n",
      "121542: reward: -420.00, mean_100: -165.55, episodes: 685, epsilon: 0.010\n",
      "122042: reward: -500.00, mean_100: -168.38, episodes: 686, epsilon: 0.010\n",
      "122542: reward: -500.00, mean_100: -172.50, episodes: 687, epsilon: 0.010\n",
      "122849: reward: -306.00, mean_100: -174.71, episodes: 688, epsilon: 0.010\n",
      "123161: reward: -311.00, mean_100: -176.97, episodes: 689, epsilon: 0.010\n",
      "123643: reward: -481.00, mean_100: -180.83, episodes: 690, epsilon: 0.010\n",
      "123864: reward: -220.00, mean_100: -182.27, episodes: 691, epsilon: 0.010\n",
      "124202: reward: -337.00, mean_100: -184.86, episodes: 692, epsilon: 0.010\n",
      "124596: reward: -393.00, mean_100: -187.94, episodes: 693, epsilon: 0.010\n",
      "124686: reward: -89.00, mean_100: -188.07, episodes: 694, epsilon: 0.010\n",
      "124815: reward: -128.00, mean_100: -188.58, episodes: 695, epsilon: 0.010\n",
      "124937: reward: -121.00, mean_100: -189.03, episodes: 696, epsilon: 0.010\n",
      "125311: reward: -373.00, mean_100: -191.86, episodes: 697, epsilon: 0.010\n",
      "125386: reward: -74.00, mean_100: -191.77, episodes: 698, epsilon: 0.010\n",
      "125500: reward: -113.00, mean_100: -192.16, episodes: 699, epsilon: 0.010\n",
      "125587: reward: -86.00, mean_100: -192.33, episodes: 700, epsilon: 0.010\n",
      "125588: reward: -1.00, mean_100: -192.34, episodes: 701, epsilon: 0.010\n",
      "125685: reward: -96.00, mean_100: -192.23, episodes: 702, epsilon: 0.010\n",
      "125810: reward: -124.00, mean_100: -192.73, episodes: 703, epsilon: 0.010\n",
      "125919: reward: -108.00, mean_100: -192.95, episodes: 704, epsilon: 0.010\n",
      "126003: reward: -83.00, mean_100: -192.84, episodes: 705, epsilon: 0.010\n",
      "126081: reward: -77.00, mean_100: -192.80, episodes: 706, epsilon: 0.010\n",
      "126158: reward: -76.00, mean_100: -192.86, episodes: 707, epsilon: 0.010\n",
      "126248: reward: -89.00, mean_100: -192.30, episodes: 708, epsilon: 0.010\n",
      "126319: reward: -70.00, mean_100: -191.98, episodes: 709, epsilon: 0.010\n",
      "126391: reward: -71.00, mean_100: -189.76, episodes: 710, epsilon: 0.010\n",
      "126466: reward: -74.00, mean_100: -189.23, episodes: 711, epsilon: 0.010\n",
      "126543: reward: -76.00, mean_100: -187.26, episodes: 712, epsilon: 0.010\n",
      "126628: reward: -84.00, mean_100: -186.83, episodes: 713, epsilon: 0.010\n",
      "126700: reward: -71.00, mean_100: -182.54, episodes: 714, epsilon: 0.010\n",
      "126794: reward: -93.00, mean_100: -178.47, episodes: 715, epsilon: 0.010\n",
      "126879: reward: -84.00, mean_100: -174.31, episodes: 716, epsilon: 0.010\n",
      "126970: reward: -90.00, mean_100: -170.21, episodes: 717, epsilon: 0.010\n",
      "127045: reward: -74.00, mean_100: -168.73, episodes: 718, epsilon: 0.010\n",
      "127116: reward: -70.00, mean_100: -164.43, episodes: 719, epsilon: 0.010\n",
      "127207: reward: -90.00, mean_100: -162.79, episodes: 720, epsilon: 0.010\n",
      "127303: reward: -95.00, mean_100: -162.10, episodes: 721, epsilon: 0.010\n",
      "127401: reward: -97.00, mean_100: -161.75, episodes: 722, epsilon: 0.010\n",
      "127477: reward: -75.00, mean_100: -161.86, episodes: 723, epsilon: 0.010\n",
      "127658: reward: -180.00, mean_100: -162.83, episodes: 724, epsilon: 0.010\n",
      "128128: reward: -469.00, mean_100: -166.36, episodes: 725, epsilon: 0.010\n",
      "128434: reward: -305.00, mean_100: -168.29, episodes: 726, epsilon: 0.010\n",
      "128934: reward: -500.00, mean_100: -172.65, episodes: 727, epsilon: 0.010\n",
      "129095: reward: -160.00, mean_100: -173.04, episodes: 728, epsilon: 0.010\n",
      "129344: reward: -248.00, mean_100: -174.80, episodes: 729, epsilon: 0.010\n",
      "129844: reward: -500.00, mean_100: -178.91, episodes: 730, epsilon: 0.010\n",
      "130344: reward: -500.00, mean_100: -183.03, episodes: 731, epsilon: 0.010\n",
      "130461: reward: -116.00, mean_100: -182.96, episodes: 732, epsilon: 0.010\n",
      "130684: reward: -222.00, mean_100: -184.22, episodes: 733, epsilon: 0.010\n",
      "130856: reward: -171.00, mean_100: -185.07, episodes: 734, epsilon: 0.010\n",
      "131059: reward: -202.00, mean_100: -186.24, episodes: 735, epsilon: 0.010\n",
      "131154: reward: -94.00, mean_100: -186.43, episodes: 736, epsilon: 0.010\n",
      "131654: reward: -500.00, mean_100: -190.30, episodes: 737, epsilon: 0.010\n",
      "131997: reward: -342.00, mean_100: -193.12, episodes: 738, epsilon: 0.010\n",
      "132079: reward: -81.00, mean_100: -188.93, episodes: 739, epsilon: 0.010\n",
      "132160: reward: -80.00, mean_100: -188.82, episodes: 740, epsilon: 0.010\n",
      "132257: reward: -96.00, mean_100: -189.01, episodes: 741, epsilon: 0.010\n",
      "132345: reward: -87.00, mean_100: -188.97, episodes: 742, epsilon: 0.010\n",
      "132450: reward: -104.00, mean_100: -189.38, episodes: 743, epsilon: 0.010\n",
      "132541: reward: -90.00, mean_100: -189.52, episodes: 744, epsilon: 0.010\n",
      "132631: reward: -89.00, mean_100: -189.52, episodes: 745, epsilon: 0.010\n",
      "132701: reward: -69.00, mean_100: -189.35, episodes: 746, epsilon: 0.010\n",
      "132789: reward: -87.00, mean_100: -189.22, episodes: 747, epsilon: 0.010\n",
      "132870: reward: -80.00, mean_100: -189.26, episodes: 748, epsilon: 0.010\n",
      "132959: reward: -88.00, mean_100: -189.16, episodes: 749, epsilon: 0.010\n",
      "133084: reward: -124.00, mean_100: -189.29, episodes: 750, epsilon: 0.010\n",
      "133156: reward: -71.00, mean_100: -189.13, episodes: 751, epsilon: 0.010\n",
      "133234: reward: -77.00, mean_100: -184.90, episodes: 752, epsilon: 0.010\n",
      "133309: reward: -74.00, mean_100: -180.64, episodes: 753, epsilon: 0.010\n",
      "133421: reward: -111.00, mean_100: -176.75, episodes: 754, epsilon: 0.010\n",
      "133498: reward: -76.00, mean_100: -172.51, episodes: 755, epsilon: 0.010\n",
      "133593: reward: -94.00, mean_100: -169.19, episodes: 756, epsilon: 0.010\n",
      "133677: reward: -83.00, mean_100: -165.02, episodes: 757, epsilon: 0.010\n",
      "133755: reward: -77.00, mean_100: -160.79, episodes: 758, epsilon: 0.010\n",
      "133826: reward: -70.00, mean_100: -156.63, episodes: 759, epsilon: 0.010\n",
      "133915: reward: -88.00, mean_100: -153.22, episodes: 760, epsilon: 0.010\n",
      "134003: reward: -87.00, mean_100: -153.35, episodes: 761, epsilon: 0.010\n",
      "134101: reward: -97.00, mean_100: -153.55, episodes: 762, epsilon: 0.010\n",
      "134179: reward: -77.00, mean_100: -152.85, episodes: 763, epsilon: 0.010\n",
      "134255: reward: -75.00, mean_100: -151.98, episodes: 764, epsilon: 0.010\n",
      "134328: reward: -72.00, mean_100: -151.78, episodes: 765, epsilon: 0.010\n",
      "134417: reward: -88.00, mean_100: -151.88, episodes: 766, epsilon: 0.010\n",
      "134917: reward: -500.00, mean_100: -156.14, episodes: 767, epsilon: 0.010\n",
      "135028: reward: -110.00, mean_100: -156.38, episodes: 768, epsilon: 0.010\n",
      "135121: reward: -92.00, mean_100: -156.59, episodes: 769, epsilon: 0.010\n",
      "135212: reward: -90.00, mean_100: -156.54, episodes: 770, epsilon: 0.010\n",
      "135297: reward: -84.00, mean_100: -156.42, episodes: 771, epsilon: 0.010\n",
      "135370: reward: -72.00, mean_100: -156.14, episodes: 772, epsilon: 0.010\n",
      "135443: reward: -72.00, mean_100: -156.11, episodes: 773, epsilon: 0.010\n",
      "135521: reward: -77.00, mean_100: -155.93, episodes: 774, epsilon: 0.010\n",
      "136021: reward: -500.00, mean_100: -160.18, episodes: 775, epsilon: 0.010\n",
      "136086: reward: -64.00, mean_100: -159.94, episodes: 776, epsilon: 0.010\n",
      "136160: reward: -73.00, mean_100: -159.80, episodes: 777, epsilon: 0.010\n",
      "136262: reward: -101.00, mean_100: -159.87, episodes: 778, epsilon: 0.010\n",
      "136356: reward: -93.00, mean_100: -159.94, episodes: 779, epsilon: 0.010\n",
      "136429: reward: -72.00, mean_100: -159.69, episodes: 780, epsilon: 0.010\n",
      "136506: reward: -76.00, mean_100: -157.51, episodes: 781, epsilon: 0.010\n",
      "136593: reward: -86.00, mean_100: -156.40, episodes: 782, epsilon: 0.010\n",
      "136795: reward: -201.00, mean_100: -157.36, episodes: 783, epsilon: 0.010\n",
      "136908: reward: -112.00, mean_100: -156.96, episodes: 784, epsilon: 0.010\n",
      "137008: reward: -99.00, mean_100: -153.75, episodes: 785, epsilon: 0.010\n",
      "137079: reward: -70.00, mean_100: -149.45, episodes: 786, epsilon: 0.010\n",
      "137190: reward: -110.00, mean_100: -145.55, episodes: 787, epsilon: 0.010\n",
      "137263: reward: -72.00, mean_100: -143.21, episodes: 788, epsilon: 0.010\n",
      "137347: reward: -83.00, mean_100: -140.93, episodes: 789, epsilon: 0.010\n",
      "137432: reward: -84.00, mean_100: -136.96, episodes: 790, epsilon: 0.010\n",
      "137503: reward: -70.00, mean_100: -135.46, episodes: 791, epsilon: 0.010\n",
      "137583: reward: -79.00, mean_100: -132.88, episodes: 792, epsilon: 0.010\n",
      "137681: reward: -97.00, mean_100: -129.92, episodes: 793, epsilon: 0.010\n",
      "137783: reward: -101.00, mean_100: -130.04, episodes: 794, epsilon: 0.010\n",
      "137872: reward: -88.00, mean_100: -129.64, episodes: 795, epsilon: 0.010\n",
      "137937: reward: -64.00, mean_100: -129.07, episodes: 796, epsilon: 0.010\n",
      "138056: reward: -118.00, mean_100: -126.52, episodes: 797, epsilon: 0.010\n",
      "138134: reward: -77.00, mean_100: -126.55, episodes: 798, epsilon: 0.010\n",
      "138204: reward: -69.00, mean_100: -126.11, episodes: 799, epsilon: 0.010\n",
      "138296: reward: -91.00, mean_100: -126.16, episodes: 800, epsilon: 0.010\n",
      "138297: reward: 0.00, mean_100: -126.15, episodes: 801, epsilon: 0.010\n",
      "138381: reward: -83.00, mean_100: -126.02, episodes: 802, epsilon: 0.010\n",
      "138467: reward: -85.00, mean_100: -125.63, episodes: 803, epsilon: 0.010\n",
      "138545: reward: -77.00, mean_100: -125.32, episodes: 804, epsilon: 0.010\n",
      "138621: reward: -75.00, mean_100: -125.24, episodes: 805, epsilon: 0.010\n",
      "138727: reward: -105.00, mean_100: -125.52, episodes: 806, epsilon: 0.010\n",
      "138807: reward: -79.00, mean_100: -125.55, episodes: 807, epsilon: 0.010\n",
      "138895: reward: -87.00, mean_100: -125.53, episodes: 808, epsilon: 0.010\n",
      "138971: reward: -75.00, mean_100: -125.58, episodes: 809, epsilon: 0.010\n",
      "139043: reward: -71.00, mean_100: -125.58, episodes: 810, epsilon: 0.010\n",
      "139124: reward: -80.00, mean_100: -125.64, episodes: 811, epsilon: 0.010\n",
      "139202: reward: -77.00, mean_100: -125.65, episodes: 812, epsilon: 0.010\n",
      "139270: reward: -67.00, mean_100: -125.48, episodes: 813, epsilon: 0.010\n",
      "139344: reward: -73.00, mean_100: -125.50, episodes: 814, epsilon: 0.010\n",
      "139413: reward: -68.00, mean_100: -125.25, episodes: 815, epsilon: 0.010\n",
      "139548: reward: -134.00, mean_100: -125.75, episodes: 816, epsilon: 0.010\n",
      "139628: reward: -79.00, mean_100: -125.64, episodes: 817, epsilon: 0.010\n",
      "139711: reward: -82.00, mean_100: -125.72, episodes: 818, epsilon: 0.010\n",
      "139837: reward: -125.00, mean_100: -126.27, episodes: 819, epsilon: 0.010\n",
      "139936: reward: -98.00, mean_100: -126.35, episodes: 820, epsilon: 0.010\n",
      "140012: reward: -75.00, mean_100: -126.15, episodes: 821, epsilon: 0.010\n",
      "140097: reward: -84.00, mean_100: -126.02, episodes: 822, epsilon: 0.010\n",
      "140172: reward: -74.00, mean_100: -126.01, episodes: 823, epsilon: 0.010\n",
      "140440: reward: -267.00, mean_100: -126.88, episodes: 824, epsilon: 0.010\n",
      "140515: reward: -74.00, mean_100: -122.93, episodes: 825, epsilon: 0.010\n",
      "140625: reward: -109.00, mean_100: -120.97, episodes: 826, epsilon: 0.010\n",
      "140687: reward: -61.00, mean_100: -116.58, episodes: 827, epsilon: 0.010\n",
      "140781: reward: -93.00, mean_100: -115.91, episodes: 828, epsilon: 0.010\n",
      "140875: reward: -93.00, mean_100: -114.36, episodes: 829, epsilon: 0.010\n",
      "140961: reward: -85.00, mean_100: -110.21, episodes: 830, epsilon: 0.010\n",
      "141036: reward: -74.00, mean_100: -105.95, episodes: 831, epsilon: 0.010\n",
      "141107: reward: -70.00, mean_100: -105.49, episodes: 832, epsilon: 0.010\n",
      "141201: reward: -93.00, mean_100: -104.20, episodes: 833, epsilon: 0.010\n",
      "141265: reward: -63.00, mean_100: -103.12, episodes: 834, epsilon: 0.010\n",
      "141343: reward: -77.00, mean_100: -101.87, episodes: 835, epsilon: 0.010\n",
      "141419: reward: -75.00, mean_100: -101.68, episodes: 836, epsilon: 0.010\n",
      "141498: reward: -78.00, mean_100: -97.46, episodes: 837, epsilon: 0.010\n",
      "141584: reward: -85.00, mean_100: -94.89, episodes: 838, epsilon: 0.010\n",
      "141654: reward: -69.00, mean_100: -94.77, episodes: 839, epsilon: 0.010\n",
      "141730: reward: -75.00, mean_100: -94.72, episodes: 840, epsilon: 0.010\n",
      "141846: reward: -115.00, mean_100: -94.91, episodes: 841, epsilon: 0.010\n",
      "141922: reward: -75.00, mean_100: -94.79, episodes: 842, epsilon: 0.010\n",
      "141997: reward: -74.00, mean_100: -94.49, episodes: 843, epsilon: 0.010\n",
      "142073: reward: -75.00, mean_100: -94.34, episodes: 844, epsilon: 0.010\n",
      "142151: reward: -77.00, mean_100: -94.22, episodes: 845, epsilon: 0.010\n",
      "142225: reward: -73.00, mean_100: -94.26, episodes: 846, epsilon: 0.010\n",
      "142316: reward: -90.00, mean_100: -94.29, episodes: 847, epsilon: 0.010\n",
      "142408: reward: -91.00, mean_100: -94.40, episodes: 848, epsilon: 0.010\n",
      "142484: reward: -75.00, mean_100: -94.27, episodes: 849, epsilon: 0.010\n",
      "142571: reward: -86.00, mean_100: -93.89, episodes: 850, epsilon: 0.010\n",
      "142659: reward: -87.00, mean_100: -94.05, episodes: 851, epsilon: 0.010\n",
      "142737: reward: -77.00, mean_100: -94.05, episodes: 852, epsilon: 0.010\n",
      "142864: reward: -126.00, mean_100: -94.57, episodes: 853, epsilon: 0.010\n",
      "142957: reward: -92.00, mean_100: -94.38, episodes: 854, epsilon: 0.010\n",
      "143038: reward: -80.00, mean_100: -94.42, episodes: 855, epsilon: 0.010\n",
      "143110: reward: -71.00, mean_100: -94.19, episodes: 856, epsilon: 0.010\n",
      "143197: reward: -86.00, mean_100: -94.22, episodes: 857, epsilon: 0.010\n",
      "143283: reward: -85.00, mean_100: -94.30, episodes: 858, epsilon: 0.010\n",
      "143360: reward: -76.00, mean_100: -94.36, episodes: 859, epsilon: 0.010\n",
      "143463: reward: -102.00, mean_100: -94.50, episodes: 860, epsilon: 0.010\n",
      "143571: reward: -107.00, mean_100: -94.70, episodes: 861, epsilon: 0.010\n",
      "143635: reward: -63.00, mean_100: -94.36, episodes: 862, epsilon: 0.010\n",
      "143719: reward: -83.00, mean_100: -94.42, episodes: 863, epsilon: 0.010\n",
      "143804: reward: -84.00, mean_100: -94.51, episodes: 864, epsilon: 0.010\n",
      "143883: reward: -78.00, mean_100: -94.57, episodes: 865, epsilon: 0.010\n",
      "144021: reward: -137.00, mean_100: -95.06, episodes: 866, epsilon: 0.010\n",
      "144109: reward: -87.00, mean_100: -90.93, episodes: 867, epsilon: 0.010\n",
      "144172: reward: -62.00, mean_100: -90.45, episodes: 868, epsilon: 0.010\n",
      "144237: reward: -64.00, mean_100: -90.17, episodes: 869, epsilon: 0.010\n",
      "144366: reward: -128.00, mean_100: -90.55, episodes: 870, epsilon: 0.010\n",
      "144436: reward: -69.00, mean_100: -90.40, episodes: 871, epsilon: 0.010\n",
      "144509: reward: -72.00, mean_100: -90.40, episodes: 872, epsilon: 0.010\n",
      "144585: reward: -75.00, mean_100: -90.43, episodes: 873, epsilon: 0.010\n",
      "144690: reward: -104.00, mean_100: -90.70, episodes: 874, epsilon: 0.010\n",
      "144864: reward: -173.00, mean_100: -87.43, episodes: 875, epsilon: 0.010\n",
      "144942: reward: -77.00, mean_100: -87.56, episodes: 876, epsilon: 0.010\n",
      "145076: reward: -133.00, mean_100: -88.16, episodes: 877, epsilon: 0.010\n",
      "145151: reward: -74.00, mean_100: -87.89, episodes: 878, epsilon: 0.010\n",
      "145227: reward: -75.00, mean_100: -87.71, episodes: 879, epsilon: 0.010\n",
      "145310: reward: -82.00, mean_100: -87.81, episodes: 880, epsilon: 0.010\n",
      "145388: reward: -77.00, mean_100: -87.82, episodes: 881, epsilon: 0.010\n",
      "145479: reward: -90.00, mean_100: -87.86, episodes: 882, epsilon: 0.010\n",
      "145549: reward: -69.00, mean_100: -86.54, episodes: 883, epsilon: 0.010\n",
      "145625: reward: -75.00, mean_100: -86.17, episodes: 884, epsilon: 0.010\n",
      "145828: reward: -202.00, mean_100: -87.20, episodes: 885, epsilon: 0.010\n",
      "145934: reward: -105.00, mean_100: -87.55, episodes: 886, epsilon: 0.010\n",
      "146005: reward: -70.00, mean_100: -87.15, episodes: 887, epsilon: 0.010\n",
      "146097: reward: -91.00, mean_100: -87.34, episodes: 888, epsilon: 0.010\n",
      "146169: reward: -71.00, mean_100: -87.22, episodes: 889, epsilon: 0.010\n",
      "146267: reward: -97.00, mean_100: -87.35, episodes: 890, epsilon: 0.010\n",
      "146342: reward: -74.00, mean_100: -87.39, episodes: 891, epsilon: 0.010\n",
      "146405: reward: -62.00, mean_100: -87.22, episodes: 892, epsilon: 0.010\n",
      "146482: reward: -76.00, mean_100: -87.01, episodes: 893, epsilon: 0.010\n",
      "146600: reward: -117.00, mean_100: -87.17, episodes: 894, epsilon: 0.010\n",
      "146663: reward: -62.00, mean_100: -86.91, episodes: 895, epsilon: 0.010\n",
      "146778: reward: -114.00, mean_100: -87.41, episodes: 896, epsilon: 0.010\n",
      "146894: reward: -115.00, mean_100: -87.38, episodes: 897, epsilon: 0.010\n",
      "146983: reward: -88.00, mean_100: -87.49, episodes: 898, epsilon: 0.010\n",
      "147073: reward: -89.00, mean_100: -87.69, episodes: 899, epsilon: 0.010\n",
      "147145: reward: -71.00, mean_100: -87.49, episodes: 900, epsilon: 0.010\n",
      "147146: reward: 0.00, mean_100: -87.49, episodes: 901, epsilon: 0.010\n",
      "147250: reward: -103.00, mean_100: -87.69, episodes: 902, epsilon: 0.010\n",
      "147358: reward: -107.00, mean_100: -87.91, episodes: 903, epsilon: 0.010\n",
      "147451: reward: -92.00, mean_100: -88.06, episodes: 904, epsilon: 0.010\n",
      "147529: reward: -77.00, mean_100: -88.08, episodes: 905, epsilon: 0.010\n",
      "147592: reward: -62.00, mean_100: -87.65, episodes: 906, epsilon: 0.010\n",
      "147667: reward: -74.00, mean_100: -87.60, episodes: 907, epsilon: 0.010\n",
      "147744: reward: -76.00, mean_100: -87.49, episodes: 908, epsilon: 0.010\n",
      "147846: reward: -101.00, mean_100: -87.75, episodes: 909, epsilon: 0.010\n",
      "147924: reward: -77.00, mean_100: -87.81, episodes: 910, epsilon: 0.010\n",
      "148012: reward: -87.00, mean_100: -87.88, episodes: 911, epsilon: 0.010\n",
      "148145: reward: -132.00, mean_100: -88.43, episodes: 912, epsilon: 0.010\n",
      "148221: reward: -75.00, mean_100: -88.51, episodes: 913, epsilon: 0.010\n",
      "148293: reward: -71.00, mean_100: -88.49, episodes: 914, epsilon: 0.010\n",
      "148372: reward: -78.00, mean_100: -88.59, episodes: 915, epsilon: 0.010\n",
      "148508: reward: -135.00, mean_100: -88.60, episodes: 916, epsilon: 0.010\n",
      "148662: reward: -153.00, mean_100: -89.34, episodes: 917, epsilon: 0.010\n",
      "148739: reward: -76.00, mean_100: -89.28, episodes: 918, epsilon: 0.010\n",
      "148831: reward: -91.00, mean_100: -88.94, episodes: 919, epsilon: 0.010\n",
      "148895: reward: -63.00, mean_100: -88.59, episodes: 920, epsilon: 0.010\n",
      "148969: reward: -73.00, mean_100: -88.57, episodes: 921, epsilon: 0.010\n",
      "149034: reward: -64.00, mean_100: -88.37, episodes: 922, epsilon: 0.010\n",
      "149110: reward: -75.00, mean_100: -88.38, episodes: 923, epsilon: 0.010\n",
      "149204: reward: -93.00, mean_100: -86.64, episodes: 924, epsilon: 0.010\n",
      "149288: reward: -83.00, mean_100: -86.73, episodes: 925, epsilon: 0.010\n",
      "149365: reward: -76.00, mean_100: -86.40, episodes: 926, epsilon: 0.010\n",
      "149465: reward: -99.00, mean_100: -86.78, episodes: 927, epsilon: 0.010\n",
      "149554: reward: -88.00, mean_100: -86.73, episodes: 928, epsilon: 0.010\n",
      "149619: reward: -64.00, mean_100: -86.44, episodes: 929, epsilon: 0.010\n",
      "149707: reward: -87.00, mean_100: -86.46, episodes: 930, epsilon: 0.010\n",
      "149784: reward: -76.00, mean_100: -86.48, episodes: 931, epsilon: 0.010\n",
      "149876: reward: -91.00, mean_100: -86.69, episodes: 932, epsilon: 0.010\n",
      "149973: reward: -96.00, mean_100: -86.72, episodes: 933, epsilon: 0.010\n",
      "150045: reward: -71.00, mean_100: -86.80, episodes: 934, epsilon: 0.010\n",
      "150138: reward: -92.00, mean_100: -86.95, episodes: 935, epsilon: 0.010\n",
      "150216: reward: -77.00, mean_100: -86.97, episodes: 936, epsilon: 0.010\n",
      "150295: reward: -78.00, mean_100: -86.97, episodes: 937, epsilon: 0.010\n",
      "150406: reward: -110.00, mean_100: -87.22, episodes: 938, epsilon: 0.010\n",
      "150484: reward: -77.00, mean_100: -87.30, episodes: 939, epsilon: 0.010\n",
      "150561: reward: -76.00, mean_100: -87.31, episodes: 940, epsilon: 0.010\n",
      "150638: reward: -76.00, mean_100: -86.92, episodes: 941, epsilon: 0.010\n",
      "150712: reward: -73.00, mean_100: -86.90, episodes: 942, epsilon: 0.010\n",
      "150809: reward: -96.00, mean_100: -87.12, episodes: 943, epsilon: 0.010\n",
      "150890: reward: -80.00, mean_100: -87.17, episodes: 944, epsilon: 0.010\n",
      "150967: reward: -76.00, mean_100: -87.16, episodes: 945, epsilon: 0.010\n",
      "151046: reward: -78.00, mean_100: -87.21, episodes: 946, epsilon: 0.010\n",
      "151144: reward: -97.00, mean_100: -87.28, episodes: 947, epsilon: 0.010\n",
      "151358: reward: -213.00, mean_100: -88.50, episodes: 948, epsilon: 0.010\n",
      "151433: reward: -74.00, mean_100: -88.49, episodes: 949, epsilon: 0.010\n",
      "151512: reward: -78.00, mean_100: -88.41, episodes: 950, epsilon: 0.010\n",
      "151635: reward: -122.00, mean_100: -88.76, episodes: 951, epsilon: 0.010\n",
      "151698: reward: -62.00, mean_100: -88.61, episodes: 952, epsilon: 0.010\n",
      "151776: reward: -77.00, mean_100: -88.12, episodes: 953, epsilon: 0.010\n",
      "151852: reward: -75.00, mean_100: -87.95, episodes: 954, epsilon: 0.010\n",
      "151936: reward: -83.00, mean_100: -87.98, episodes: 955, epsilon: 0.010\n",
      "152011: reward: -74.00, mean_100: -88.01, episodes: 956, epsilon: 0.010\n",
      "152097: reward: -85.00, mean_100: -88.00, episodes: 957, epsilon: 0.010\n",
      "152172: reward: -74.00, mean_100: -87.89, episodes: 958, epsilon: 0.010\n",
      "152259: reward: -86.00, mean_100: -87.99, episodes: 959, epsilon: 0.010\n",
      "152344: reward: -84.00, mean_100: -87.81, episodes: 960, epsilon: 0.010\n",
      "152450: reward: -105.00, mean_100: -87.79, episodes: 961, epsilon: 0.010\n",
      "152537: reward: -86.00, mean_100: -88.02, episodes: 962, epsilon: 0.010\n",
      "152609: reward: -71.00, mean_100: -87.90, episodes: 963, epsilon: 0.010\n",
      "152704: reward: -94.00, mean_100: -88.00, episodes: 964, epsilon: 0.010\n",
      "152774: reward: -69.00, mean_100: -87.91, episodes: 965, epsilon: 0.010\n",
      "152853: reward: -78.00, mean_100: -87.32, episodes: 966, epsilon: 0.010\n",
      "152939: reward: -85.00, mean_100: -87.30, episodes: 967, epsilon: 0.010\n",
      "153027: reward: -87.00, mean_100: -87.55, episodes: 968, epsilon: 0.010\n",
      "153120: reward: -92.00, mean_100: -87.83, episodes: 969, epsilon: 0.010\n",
      "153198: reward: -77.00, mean_100: -87.32, episodes: 970, epsilon: 0.010\n",
      "153272: reward: -73.00, mean_100: -87.36, episodes: 971, epsilon: 0.010\n",
      "153341: reward: -68.00, mean_100: -87.32, episodes: 972, epsilon: 0.010\n",
      "153424: reward: -82.00, mean_100: -87.39, episodes: 973, epsilon: 0.010\n",
      "153511: reward: -86.00, mean_100: -87.21, episodes: 974, epsilon: 0.010\n",
      "153600: reward: -88.00, mean_100: -86.36, episodes: 975, epsilon: 0.010\n",
      "153708: reward: -107.00, mean_100: -86.66, episodes: 976, epsilon: 0.010\n",
      "153780: reward: -71.00, mean_100: -86.04, episodes: 977, epsilon: 0.010\n",
      "153868: reward: -87.00, mean_100: -86.17, episodes: 978, epsilon: 0.010\n",
      "153982: reward: -113.00, mean_100: -86.55, episodes: 979, epsilon: 0.010\n",
      "154053: reward: -70.00, mean_100: -86.43, episodes: 980, epsilon: 0.010\n",
      "154125: reward: -71.00, mean_100: -86.37, episodes: 981, epsilon: 0.010\n",
      "154212: reward: -86.00, mean_100: -86.33, episodes: 982, epsilon: 0.010\n",
      "154357: reward: -144.00, mean_100: -87.08, episodes: 983, epsilon: 0.010\n",
      "154443: reward: -85.00, mean_100: -87.18, episodes: 984, epsilon: 0.010\n",
      "154516: reward: -72.00, mean_100: -85.88, episodes: 985, epsilon: 0.010\n",
      "154626: reward: -109.00, mean_100: -85.92, episodes: 986, epsilon: 0.010\n",
      "154698: reward: -71.00, mean_100: -85.93, episodes: 987, epsilon: 0.010\n",
      "154782: reward: -83.00, mean_100: -85.85, episodes: 988, epsilon: 0.010\n",
      "154871: reward: -88.00, mean_100: -86.02, episodes: 989, epsilon: 0.010\n",
      "154935: reward: -63.00, mean_100: -85.68, episodes: 990, epsilon: 0.010\n",
      "155008: reward: -72.00, mean_100: -85.66, episodes: 991, epsilon: 0.010\n",
      "155079: reward: -70.00, mean_100: -85.74, episodes: 992, epsilon: 0.010\n",
      "155188: reward: -108.00, mean_100: -86.06, episodes: 993, epsilon: 0.010\n",
      "155275: reward: -86.00, mean_100: -85.75, episodes: 994, epsilon: 0.010\n",
      "155346: reward: -70.00, mean_100: -85.83, episodes: 995, epsilon: 0.010\n",
      "155527: reward: -180.00, mean_100: -86.49, episodes: 996, epsilon: 0.010\n",
      "155614: reward: -86.00, mean_100: -86.20, episodes: 997, epsilon: 0.010\n",
      "155686: reward: -71.00, mean_100: -86.03, episodes: 998, epsilon: 0.010\n",
      "155778: reward: -91.00, mean_100: -86.05, episodes: 999, epsilon: 0.010\n",
      "155900: reward: -121.00, mean_100: -86.55, episodes: 1000, epsilon: 0.010\n",
      "155907: reward: -6.00, mean_100: -86.61, episodes: 1001, epsilon: 0.010\n",
      "155987: reward: -79.00, mean_100: -86.37, episodes: 1002, epsilon: 0.010\n",
      "156053: reward: -65.00, mean_100: -85.95, episodes: 1003, epsilon: 0.010\n",
      "156142: reward: -88.00, mean_100: -85.91, episodes: 1004, epsilon: 0.010\n",
      "156233: reward: -90.00, mean_100: -86.04, episodes: 1005, epsilon: 0.010\n",
      "156321: reward: -87.00, mean_100: -86.29, episodes: 1006, epsilon: 0.010\n",
      "156404: reward: -82.00, mean_100: -86.37, episodes: 1007, epsilon: 0.010\n",
      "156475: reward: -70.00, mean_100: -86.31, episodes: 1008, epsilon: 0.010\n",
      "156598: reward: -122.00, mean_100: -86.52, episodes: 1009, epsilon: 0.010\n",
      "156728: reward: -129.00, mean_100: -87.04, episodes: 1010, epsilon: 0.010\n",
      "156799: reward: -70.00, mean_100: -86.87, episodes: 1011, epsilon: 0.010\n",
      "156882: reward: -82.00, mean_100: -86.37, episodes: 1012, epsilon: 0.010\n",
      "156971: reward: -88.00, mean_100: -86.50, episodes: 1013, epsilon: 0.010\n",
      "157051: reward: -79.00, mean_100: -86.58, episodes: 1014, epsilon: 0.010\n",
      "157143: reward: -91.00, mean_100: -86.71, episodes: 1015, epsilon: 0.010\n",
      "157282: reward: -138.00, mean_100: -86.74, episodes: 1016, epsilon: 0.010\n",
      "157353: reward: -70.00, mean_100: -85.91, episodes: 1017, epsilon: 0.010\n",
      "157424: reward: -70.00, mean_100: -85.85, episodes: 1018, epsilon: 0.010\n",
      "157507: reward: -82.00, mean_100: -85.76, episodes: 1019, epsilon: 0.010\n",
      "157578: reward: -70.00, mean_100: -85.83, episodes: 1020, epsilon: 0.010\n",
      "157695: reward: -116.00, mean_100: -86.26, episodes: 1021, epsilon: 0.010\n",
      "157810: reward: -114.00, mean_100: -86.76, episodes: 1022, epsilon: 0.010\n",
      "157874: reward: -63.00, mean_100: -86.64, episodes: 1023, epsilon: 0.010\n",
      "157959: reward: -84.00, mean_100: -86.55, episodes: 1024, epsilon: 0.010\n",
      "158035: reward: -75.00, mean_100: -86.47, episodes: 1025, epsilon: 0.010\n",
      "158110: reward: -74.00, mean_100: -86.45, episodes: 1026, epsilon: 0.010\n",
      "158202: reward: -91.00, mean_100: -86.37, episodes: 1027, epsilon: 0.010\n",
      "158291: reward: -88.00, mean_100: -86.37, episodes: 1028, epsilon: 0.010\n",
      "158362: reward: -70.00, mean_100: -86.43, episodes: 1029, epsilon: 0.010\n",
      "158468: reward: -105.00, mean_100: -86.61, episodes: 1030, epsilon: 0.010\n",
      "158605: reward: -136.00, mean_100: -87.21, episodes: 1031, epsilon: 0.010\n",
      "158677: reward: -71.00, mean_100: -87.01, episodes: 1032, epsilon: 0.010\n",
      "158763: reward: -85.00, mean_100: -86.90, episodes: 1033, epsilon: 0.010\n",
      "158845: reward: -81.00, mean_100: -87.00, episodes: 1034, epsilon: 0.010\n",
      "158956: reward: -110.00, mean_100: -87.18, episodes: 1035, epsilon: 0.010\n",
      "159026: reward: -69.00, mean_100: -87.10, episodes: 1036, epsilon: 0.010\n",
      "159110: reward: -83.00, mean_100: -87.15, episodes: 1037, epsilon: 0.010\n",
      "159186: reward: -75.00, mean_100: -86.80, episodes: 1038, epsilon: 0.010\n",
      "159311: reward: -124.00, mean_100: -87.27, episodes: 1039, epsilon: 0.010\n",
      "159397: reward: -85.00, mean_100: -87.36, episodes: 1040, epsilon: 0.010\n",
      "159527: reward: -129.00, mean_100: -87.89, episodes: 1041, epsilon: 0.010\n",
      "159603: reward: -75.00, mean_100: -87.91, episodes: 1042, epsilon: 0.010\n",
      "159676: reward: -72.00, mean_100: -87.67, episodes: 1043, epsilon: 0.010\n",
      "159755: reward: -78.00, mean_100: -87.65, episodes: 1044, epsilon: 0.010\n",
      "159855: reward: -99.00, mean_100: -87.88, episodes: 1045, epsilon: 0.010\n",
      "159931: reward: -75.00, mean_100: -87.85, episodes: 1046, epsilon: 0.010\n",
      "160076: reward: -144.00, mean_100: -88.32, episodes: 1047, epsilon: 0.010\n",
      "160152: reward: -75.00, mean_100: -86.94, episodes: 1048, epsilon: 0.010\n",
      "160257: reward: -104.00, mean_100: -87.24, episodes: 1049, epsilon: 0.010\n",
      "160366: reward: -108.00, mean_100: -87.54, episodes: 1050, epsilon: 0.010\n",
      "160445: reward: -78.00, mean_100: -87.10, episodes: 1051, epsilon: 0.010\n",
      "160547: reward: -101.00, mean_100: -87.49, episodes: 1052, epsilon: 0.010\n",
      "160625: reward: -77.00, mean_100: -87.49, episodes: 1053, epsilon: 0.010\n",
      "160702: reward: -76.00, mean_100: -87.50, episodes: 1054, epsilon: 0.010\n",
      "160775: reward: -72.00, mean_100: -87.39, episodes: 1055, epsilon: 0.010\n",
      "160868: reward: -92.00, mean_100: -87.57, episodes: 1056, epsilon: 0.010\n",
      "160937: reward: -68.00, mean_100: -87.40, episodes: 1057, epsilon: 0.010\n",
      "161028: reward: -90.00, mean_100: -87.56, episodes: 1058, epsilon: 0.010\n",
      "161177: reward: -148.00, mean_100: -88.18, episodes: 1059, epsilon: 0.010\n",
      "161254: reward: -76.00, mean_100: -88.10, episodes: 1060, epsilon: 0.010\n",
      "161355: reward: -100.00, mean_100: -88.05, episodes: 1061, epsilon: 0.010\n",
      "161431: reward: -75.00, mean_100: -87.94, episodes: 1062, epsilon: 0.010\n",
      "161510: reward: -78.00, mean_100: -88.01, episodes: 1063, epsilon: 0.010\n",
      "161597: reward: -86.00, mean_100: -87.93, episodes: 1064, epsilon: 0.010\n",
      "161670: reward: -72.00, mean_100: -87.96, episodes: 1065, epsilon: 0.010\n",
      "161748: reward: -77.00, mean_100: -87.95, episodes: 1066, epsilon: 0.010\n",
      "161827: reward: -78.00, mean_100: -87.88, episodes: 1067, epsilon: 0.010\n",
      "161905: reward: -77.00, mean_100: -87.78, episodes: 1068, epsilon: 0.010\n",
      "161977: reward: -71.00, mean_100: -87.57, episodes: 1069, epsilon: 0.010\n",
      "162049: reward: -71.00, mean_100: -87.51, episodes: 1070, epsilon: 0.010\n",
      "162151: reward: -101.00, mean_100: -87.79, episodes: 1071, epsilon: 0.010\n",
      "162246: reward: -94.00, mean_100: -88.05, episodes: 1072, epsilon: 0.010\n",
      "162321: reward: -74.00, mean_100: -87.97, episodes: 1073, epsilon: 0.010\n",
      "162417: reward: -95.00, mean_100: -88.06, episodes: 1074, epsilon: 0.010\n",
      "162494: reward: -76.00, mean_100: -87.94, episodes: 1075, epsilon: 0.010\n",
      "162573: reward: -78.00, mean_100: -87.65, episodes: 1076, epsilon: 0.010\n",
      "162681: reward: -107.00, mean_100: -88.01, episodes: 1077, epsilon: 0.010\n",
      "162770: reward: -88.00, mean_100: -88.02, episodes: 1078, epsilon: 0.010\n",
      "162858: reward: -87.00, mean_100: -87.76, episodes: 1079, epsilon: 0.010\n",
      "162929: reward: -70.00, mean_100: -87.76, episodes: 1080, epsilon: 0.010\n",
      "163001: reward: -71.00, mean_100: -87.76, episodes: 1081, epsilon: 0.010\n",
      "163090: reward: -88.00, mean_100: -87.78, episodes: 1082, epsilon: 0.010\n",
      "163167: reward: -76.00, mean_100: -87.10, episodes: 1083, epsilon: 0.010\n",
      "163255: reward: -87.00, mean_100: -87.12, episodes: 1084, epsilon: 0.010\n",
      "163400: reward: -144.00, mean_100: -87.84, episodes: 1085, epsilon: 0.010\n",
      "163485: reward: -84.00, mean_100: -87.59, episodes: 1086, epsilon: 0.010\n",
      "163563: reward: -77.00, mean_100: -87.65, episodes: 1087, epsilon: 0.010\n",
      "163662: reward: -98.00, mean_100: -87.80, episodes: 1088, epsilon: 0.010\n",
      "163754: reward: -91.00, mean_100: -87.83, episodes: 1089, epsilon: 0.010\n",
      "163838: reward: -83.00, mean_100: -88.03, episodes: 1090, epsilon: 0.010\n",
      "163940: reward: -101.00, mean_100: -88.32, episodes: 1091, epsilon: 0.010\n",
      "164041: reward: -100.00, mean_100: -88.62, episodes: 1092, epsilon: 0.010\n",
      "164122: reward: -80.00, mean_100: -88.34, episodes: 1093, epsilon: 0.010\n",
      "164207: reward: -84.00, mean_100: -88.32, episodes: 1094, epsilon: 0.010\n",
      "164279: reward: -71.00, mean_100: -88.33, episodes: 1095, epsilon: 0.010\n",
      "164420: reward: -140.00, mean_100: -87.93, episodes: 1096, epsilon: 0.010\n",
      "164526: reward: -105.00, mean_100: -88.12, episodes: 1097, epsilon: 0.010\n",
      "164716: reward: -189.00, mean_100: -89.30, episodes: 1098, epsilon: 0.010\n",
      "164810: reward: -93.00, mean_100: -89.32, episodes: 1099, epsilon: 0.010\n",
      "164883: reward: -72.00, mean_100: -88.83, episodes: 1100, epsilon: 0.010\n",
      "164884: reward: 0.00, mean_100: -88.77, episodes: 1101, epsilon: 0.010\n",
      "164948: reward: -63.00, mean_100: -88.61, episodes: 1102, epsilon: 0.010\n",
      "165045: reward: -96.00, mean_100: -88.92, episodes: 1103, epsilon: 0.010\n",
      "165132: reward: -86.00, mean_100: -88.90, episodes: 1104, epsilon: 0.010\n",
      "165208: reward: -75.00, mean_100: -88.75, episodes: 1105, epsilon: 0.010\n",
      "165294: reward: -85.00, mean_100: -88.73, episodes: 1106, epsilon: 0.010\n",
      "165414: reward: -119.00, mean_100: -89.10, episodes: 1107, epsilon: 0.010\n",
      "165503: reward: -88.00, mean_100: -89.28, episodes: 1108, epsilon: 0.010\n",
      "165586: reward: -82.00, mean_100: -88.88, episodes: 1109, epsilon: 0.010\n",
      "165656: reward: -69.00, mean_100: -88.28, episodes: 1110, epsilon: 0.010\n",
      "165719: reward: -62.00, mean_100: -88.20, episodes: 1111, epsilon: 0.010\n",
      "165799: reward: -79.00, mean_100: -88.17, episodes: 1112, epsilon: 0.010\n",
      "165876: reward: -76.00, mean_100: -88.05, episodes: 1113, epsilon: 0.010\n",
      "165980: reward: -103.00, mean_100: -88.29, episodes: 1114, epsilon: 0.010\n",
      "166052: reward: -71.00, mean_100: -88.09, episodes: 1115, epsilon: 0.010\n",
      "166136: reward: -83.00, mean_100: -87.54, episodes: 1116, epsilon: 0.010\n",
      "166219: reward: -82.00, mean_100: -87.66, episodes: 1117, epsilon: 0.010\n",
      "166318: reward: -98.00, mean_100: -87.94, episodes: 1118, epsilon: 0.010\n",
      "166407: reward: -88.00, mean_100: -88.00, episodes: 1119, epsilon: 0.010\n",
      "166481: reward: -73.00, mean_100: -88.03, episodes: 1120, epsilon: 0.010\n",
      "166544: reward: -62.00, mean_100: -87.49, episodes: 1121, epsilon: 0.010\n",
      "166630: reward: -85.00, mean_100: -87.20, episodes: 1122, epsilon: 0.010\n",
      "166701: reward: -70.00, mean_100: -87.27, episodes: 1123, epsilon: 0.010\n",
      "166795: reward: -93.00, mean_100: -87.36, episodes: 1124, epsilon: 0.010\n",
      "166905: reward: -109.00, mean_100: -87.70, episodes: 1125, epsilon: 0.010\n",
      "166994: reward: -88.00, mean_100: -87.84, episodes: 1126, epsilon: 0.010\n",
      "167070: reward: -75.00, mean_100: -87.68, episodes: 1127, epsilon: 0.010\n",
      "167153: reward: -82.00, mean_100: -87.62, episodes: 1128, epsilon: 0.010\n",
      "167223: reward: -69.00, mean_100: -87.61, episodes: 1129, epsilon: 0.010\n",
      "167317: reward: -93.00, mean_100: -87.49, episodes: 1130, epsilon: 0.010\n",
      "167399: reward: -81.00, mean_100: -86.94, episodes: 1131, epsilon: 0.010\n",
      "167471: reward: -71.00, mean_100: -86.94, episodes: 1132, epsilon: 0.010\n",
      "167557: reward: -85.00, mean_100: -86.94, episodes: 1133, epsilon: 0.010\n",
      "167635: reward: -77.00, mean_100: -86.90, episodes: 1134, epsilon: 0.010\n",
      "167708: reward: -72.00, mean_100: -86.52, episodes: 1135, epsilon: 0.010\n",
      "167796: reward: -87.00, mean_100: -86.70, episodes: 1136, epsilon: 0.010\n",
      "167891: reward: -94.00, mean_100: -86.81, episodes: 1137, epsilon: 0.010\n",
      "167976: reward: -84.00, mean_100: -86.90, episodes: 1138, epsilon: 0.010\n",
      "168047: reward: -70.00, mean_100: -86.36, episodes: 1139, epsilon: 0.010\n",
      "168133: reward: -85.00, mean_100: -86.36, episodes: 1140, epsilon: 0.010\n",
      "168229: reward: -95.00, mean_100: -86.02, episodes: 1141, epsilon: 0.010\n",
      "168327: reward: -97.00, mean_100: -86.24, episodes: 1142, epsilon: 0.010\n",
      "168425: reward: -97.00, mean_100: -86.49, episodes: 1143, epsilon: 0.010\n",
      "168528: reward: -102.00, mean_100: -86.73, episodes: 1144, epsilon: 0.010\n",
      "168604: reward: -75.00, mean_100: -86.49, episodes: 1145, epsilon: 0.010\n",
      "168702: reward: -97.00, mean_100: -86.71, episodes: 1146, epsilon: 0.010\n",
      "168773: reward: -70.00, mean_100: -85.97, episodes: 1147, epsilon: 0.010\n",
      "168883: reward: -109.00, mean_100: -86.31, episodes: 1148, epsilon: 0.010\n",
      "168968: reward: -84.00, mean_100: -86.11, episodes: 1149, epsilon: 0.010\n",
      "169043: reward: -74.00, mean_100: -85.77, episodes: 1150, epsilon: 0.010\n",
      "169114: reward: -70.00, mean_100: -85.69, episodes: 1151, epsilon: 0.010\n",
      "169200: reward: -85.00, mean_100: -85.53, episodes: 1152, epsilon: 0.010\n",
      "169292: reward: -91.00, mean_100: -85.67, episodes: 1153, epsilon: 0.010\n",
      "169392: reward: -99.00, mean_100: -85.90, episodes: 1154, epsilon: 0.010\n",
      "169480: reward: -87.00, mean_100: -86.05, episodes: 1155, epsilon: 0.010\n",
      "169552: reward: -71.00, mean_100: -85.84, episodes: 1156, epsilon: 0.010\n",
      "169649: reward: -96.00, mean_100: -86.12, episodes: 1157, epsilon: 0.010\n",
      "169726: reward: -76.00, mean_100: -85.98, episodes: 1158, epsilon: 0.010\n",
      "169811: reward: -84.00, mean_100: -85.34, episodes: 1159, epsilon: 0.010\n",
      "169886: reward: -74.00, mean_100: -85.32, episodes: 1160, epsilon: 0.010\n",
      "169957: reward: -70.00, mean_100: -85.02, episodes: 1161, epsilon: 0.010\n",
      "170033: reward: -75.00, mean_100: -85.02, episodes: 1162, epsilon: 0.010\n",
      "170105: reward: -71.00, mean_100: -84.95, episodes: 1163, epsilon: 0.010\n",
      "170193: reward: -87.00, mean_100: -84.96, episodes: 1164, epsilon: 0.010\n",
      "170268: reward: -74.00, mean_100: -84.98, episodes: 1165, epsilon: 0.010\n",
      "170360: reward: -91.00, mean_100: -85.12, episodes: 1166, epsilon: 0.010\n",
      "170439: reward: -78.00, mean_100: -85.12, episodes: 1167, epsilon: 0.010\n",
      "170512: reward: -72.00, mean_100: -85.07, episodes: 1168, epsilon: 0.010\n",
      "170593: reward: -80.00, mean_100: -85.16, episodes: 1169, epsilon: 0.010\n",
      "170679: reward: -85.00, mean_100: -85.30, episodes: 1170, epsilon: 0.010\n",
      "170770: reward: -90.00, mean_100: -85.19, episodes: 1171, epsilon: 0.010\n",
      "170857: reward: -86.00, mean_100: -85.11, episodes: 1172, epsilon: 0.010\n",
      "170927: reward: -69.00, mean_100: -85.06, episodes: 1173, epsilon: 0.010\n",
      "171037: reward: -109.00, mean_100: -85.20, episodes: 1174, epsilon: 0.010\n",
      "171133: reward: -95.00, mean_100: -85.39, episodes: 1175, epsilon: 0.010\n",
      "171209: reward: -75.00, mean_100: -85.36, episodes: 1176, epsilon: 0.010\n",
      "171295: reward: -85.00, mean_100: -85.14, episodes: 1177, epsilon: 0.010\n",
      "171381: reward: -85.00, mean_100: -85.11, episodes: 1178, epsilon: 0.010\n",
      "171486: reward: -104.00, mean_100: -85.28, episodes: 1179, epsilon: 0.010\n",
      "171556: reward: -69.00, mean_100: -85.27, episodes: 1180, epsilon: 0.010\n",
      "171618: reward: -61.00, mean_100: -85.17, episodes: 1181, epsilon: 0.010\n",
      "171690: reward: -71.00, mean_100: -85.00, episodes: 1182, epsilon: 0.010\n",
      "171789: reward: -98.00, mean_100: -85.22, episodes: 1183, epsilon: 0.010\n",
      "171870: reward: -80.00, mean_100: -85.15, episodes: 1184, epsilon: 0.010\n",
      "171941: reward: -70.00, mean_100: -84.41, episodes: 1185, epsilon: 0.010\n",
      "172025: reward: -83.00, mean_100: -84.40, episodes: 1186, epsilon: 0.010\n",
      "172114: reward: -88.00, mean_100: -84.51, episodes: 1187, epsilon: 0.010\n",
      "172198: reward: -83.00, mean_100: -84.36, episodes: 1188, epsilon: 0.010\n",
      "172284: reward: -85.00, mean_100: -84.30, episodes: 1189, epsilon: 0.010\n",
      "172390: reward: -105.00, mean_100: -84.52, episodes: 1190, epsilon: 0.010\n",
      "172485: reward: -94.00, mean_100: -84.45, episodes: 1191, epsilon: 0.010\n",
      "172575: reward: -89.00, mean_100: -84.34, episodes: 1192, epsilon: 0.010\n",
      "172669: reward: -93.00, mean_100: -84.47, episodes: 1193, epsilon: 0.010\n",
      "172761: reward: -91.00, mean_100: -84.54, episodes: 1194, epsilon: 0.010\n",
      "172824: reward: -62.00, mean_100: -84.45, episodes: 1195, epsilon: 0.010\n",
      "172895: reward: -70.00, mean_100: -83.75, episodes: 1196, epsilon: 0.010\n",
      "172971: reward: -75.00, mean_100: -83.45, episodes: 1197, epsilon: 0.010\n",
      "173075: reward: -103.00, mean_100: -82.59, episodes: 1198, epsilon: 0.010\n",
      "173145: reward: -69.00, mean_100: -82.35, episodes: 1199, epsilon: 0.010\n",
      "173247: reward: -101.00, mean_100: -82.64, episodes: 1200, epsilon: 0.010\n",
      "173254: reward: -6.00, mean_100: -82.70, episodes: 1201, epsilon: 0.010\n",
      "173331: reward: -76.00, mean_100: -82.83, episodes: 1202, epsilon: 0.010\n",
      "173394: reward: -62.00, mean_100: -82.49, episodes: 1203, epsilon: 0.010\n",
      "173458: reward: -63.00, mean_100: -82.26, episodes: 1204, epsilon: 0.010\n",
      "173599: reward: -140.00, mean_100: -82.91, episodes: 1205, epsilon: 0.010\n",
      "173674: reward: -74.00, mean_100: -82.80, episodes: 1206, epsilon: 0.010\n",
      "173750: reward: -75.00, mean_100: -82.36, episodes: 1207, epsilon: 0.010\n",
      "173837: reward: -86.00, mean_100: -82.34, episodes: 1208, epsilon: 0.010\n",
      "173908: reward: -70.00, mean_100: -82.22, episodes: 1209, epsilon: 0.010\n",
      "174005: reward: -96.00, mean_100: -82.49, episodes: 1210, epsilon: 0.010\n",
      "174094: reward: -88.00, mean_100: -82.75, episodes: 1211, epsilon: 0.010\n",
      "174170: reward: -75.00, mean_100: -82.71, episodes: 1212, epsilon: 0.010\n",
      "174278: reward: -107.00, mean_100: -83.02, episodes: 1213, epsilon: 0.010\n",
      "174353: reward: -74.00, mean_100: -82.73, episodes: 1214, epsilon: 0.010\n",
      "174425: reward: -71.00, mean_100: -82.73, episodes: 1215, epsilon: 0.010\n",
      "174513: reward: -87.00, mean_100: -82.77, episodes: 1216, epsilon: 0.010\n",
      "174615: reward: -101.00, mean_100: -82.96, episodes: 1217, epsilon: 0.010\n",
      "174707: reward: -91.00, mean_100: -82.89, episodes: 1218, epsilon: 0.010\n",
      "174792: reward: -84.00, mean_100: -82.85, episodes: 1219, epsilon: 0.010\n",
      "174863: reward: -70.00, mean_100: -82.82, episodes: 1220, epsilon: 0.010\n",
      "174928: reward: -64.00, mean_100: -82.84, episodes: 1221, epsilon: 0.010\n",
      "175031: reward: -102.00, mean_100: -83.01, episodes: 1222, epsilon: 0.010\n",
      "175106: reward: -74.00, mean_100: -83.05, episodes: 1223, epsilon: 0.010\n",
      "175176: reward: -69.00, mean_100: -82.81, episodes: 1224, epsilon: 0.010\n",
      "175248: reward: -71.00, mean_100: -82.43, episodes: 1225, epsilon: 0.010\n",
      "175377: reward: -128.00, mean_100: -82.83, episodes: 1226, epsilon: 0.010\n",
      "175471: reward: -93.00, mean_100: -83.01, episodes: 1227, epsilon: 0.010\n",
      "175547: reward: -75.00, mean_100: -82.94, episodes: 1228, epsilon: 0.010\n",
      "175621: reward: -73.00, mean_100: -82.98, episodes: 1229, epsilon: 0.010\n",
      "175710: reward: -88.00, mean_100: -82.93, episodes: 1230, epsilon: 0.010\n",
      "175774: reward: -63.00, mean_100: -82.75, episodes: 1231, epsilon: 0.010\n",
      "175871: reward: -96.00, mean_100: -83.00, episodes: 1232, epsilon: 0.010\n",
      "175961: reward: -89.00, mean_100: -83.04, episodes: 1233, epsilon: 0.010\n",
      "176056: reward: -94.00, mean_100: -83.21, episodes: 1234, epsilon: 0.010\n",
      "176153: reward: -96.00, mean_100: -83.45, episodes: 1235, epsilon: 0.010\n",
      "176223: reward: -69.00, mean_100: -83.27, episodes: 1236, epsilon: 0.010\n",
      "176306: reward: -82.00, mean_100: -83.15, episodes: 1237, epsilon: 0.010\n",
      "176377: reward: -70.00, mean_100: -83.01, episodes: 1238, epsilon: 0.010\n",
      "176455: reward: -77.00, mean_100: -83.08, episodes: 1239, epsilon: 0.010\n",
      "176546: reward: -90.00, mean_100: -83.13, episodes: 1240, epsilon: 0.010\n",
      "176656: reward: -109.00, mean_100: -83.27, episodes: 1241, epsilon: 0.010\n",
      "176738: reward: -81.00, mean_100: -83.11, episodes: 1242, epsilon: 0.010\n",
      "176853: reward: -114.00, mean_100: -83.28, episodes: 1243, epsilon: 0.010\n",
      "176935: reward: -81.00, mean_100: -83.07, episodes: 1244, epsilon: 0.010\n",
      "177006: reward: -70.00, mean_100: -83.02, episodes: 1245, epsilon: 0.010\n",
      "177102: reward: -95.00, mean_100: -83.00, episodes: 1246, epsilon: 0.010\n",
      "177171: reward: -68.00, mean_100: -82.98, episodes: 1247, epsilon: 0.010\n",
      "177247: reward: -75.00, mean_100: -82.64, episodes: 1248, epsilon: 0.010\n",
      "177325: reward: -77.00, mean_100: -82.57, episodes: 1249, epsilon: 0.010\n",
      "177404: reward: -78.00, mean_100: -82.61, episodes: 1250, epsilon: 0.010\n",
      "177483: reward: -78.00, mean_100: -82.69, episodes: 1251, epsilon: 0.010\n",
      "177558: reward: -74.00, mean_100: -82.58, episodes: 1252, epsilon: 0.010\n",
      "177659: reward: -100.00, mean_100: -82.67, episodes: 1253, epsilon: 0.010\n",
      "177728: reward: -68.00, mean_100: -82.36, episodes: 1254, epsilon: 0.010\n",
      "177800: reward: -71.00, mean_100: -82.20, episodes: 1255, epsilon: 0.010\n",
      "177894: reward: -93.00, mean_100: -82.42, episodes: 1256, epsilon: 0.010\n",
      "177969: reward: -74.00, mean_100: -82.20, episodes: 1257, epsilon: 0.010\n",
      "178053: reward: -83.00, mean_100: -82.27, episodes: 1258, epsilon: 0.010\n",
      "178132: reward: -78.00, mean_100: -82.21, episodes: 1259, epsilon: 0.010\n",
      "178196: reward: -63.00, mean_100: -82.10, episodes: 1260, epsilon: 0.010\n",
      "178296: reward: -99.00, mean_100: -82.39, episodes: 1261, epsilon: 0.010\n",
      "178391: reward: -94.00, mean_100: -82.58, episodes: 1262, epsilon: 0.010\n",
      "178469: reward: -77.00, mean_100: -82.64, episodes: 1263, epsilon: 0.010\n",
      "178541: reward: -71.00, mean_100: -82.48, episodes: 1264, epsilon: 0.010\n",
      "178646: reward: -104.00, mean_100: -82.78, episodes: 1265, epsilon: 0.010\n",
      "178723: reward: -76.00, mean_100: -82.63, episodes: 1266, epsilon: 0.010\n",
      "178848: reward: -124.00, mean_100: -83.09, episodes: 1267, epsilon: 0.010\n",
      "178928: reward: -79.00, mean_100: -83.16, episodes: 1268, epsilon: 0.010\n",
      "179010: reward: -81.00, mean_100: -83.17, episodes: 1269, epsilon: 0.010\n",
      "179100: reward: -89.00, mean_100: -83.21, episodes: 1270, epsilon: 0.010\n",
      "179165: reward: -64.00, mean_100: -82.95, episodes: 1271, epsilon: 0.010\n",
      "179260: reward: -94.00, mean_100: -83.03, episodes: 1272, epsilon: 0.010\n",
      "179348: reward: -87.00, mean_100: -83.21, episodes: 1273, epsilon: 0.010\n",
      "179437: reward: -88.00, mean_100: -83.00, episodes: 1274, epsilon: 0.010\n",
      "179508: reward: -70.00, mean_100: -82.75, episodes: 1275, epsilon: 0.010\n",
      "179583: reward: -74.00, mean_100: -82.74, episodes: 1276, epsilon: 0.010\n",
      "179672: reward: -88.00, mean_100: -82.77, episodes: 1277, epsilon: 0.010\n",
      "179748: reward: -75.00, mean_100: -82.67, episodes: 1278, epsilon: 0.010\n",
      "179834: reward: -85.00, mean_100: -82.48, episodes: 1279, epsilon: 0.010\n",
      "179928: reward: -93.00, mean_100: -82.72, episodes: 1280, epsilon: 0.010\n",
      "180024: reward: -95.00, mean_100: -83.06, episodes: 1281, epsilon: 0.010\n",
      "180105: reward: -80.00, mean_100: -83.15, episodes: 1282, epsilon: 0.010\n",
      "180181: reward: -75.00, mean_100: -82.92, episodes: 1283, epsilon: 0.010\n",
      "180251: reward: -69.00, mean_100: -82.81, episodes: 1284, epsilon: 0.010\n",
      "180340: reward: -88.00, mean_100: -82.99, episodes: 1285, epsilon: 0.010\n",
      "180411: reward: -70.00, mean_100: -82.86, episodes: 1286, epsilon: 0.010\n",
      "180500: reward: -88.00, mean_100: -82.86, episodes: 1287, epsilon: 0.010\n",
      "180571: reward: -70.00, mean_100: -82.73, episodes: 1288, epsilon: 0.010\n",
      "180641: reward: -69.00, mean_100: -82.57, episodes: 1289, epsilon: 0.010\n",
      "180713: reward: -71.00, mean_100: -82.23, episodes: 1290, epsilon: 0.010\n",
      "180827: reward: -113.00, mean_100: -82.42, episodes: 1291, epsilon: 0.010\n",
      "180898: reward: -70.00, mean_100: -82.23, episodes: 1292, epsilon: 0.010\n",
      "180985: reward: -86.00, mean_100: -82.16, episodes: 1293, epsilon: 0.010\n",
      "181062: reward: -76.00, mean_100: -82.01, episodes: 1294, epsilon: 0.010\n",
      "181132: reward: -69.00, mean_100: -82.08, episodes: 1295, epsilon: 0.010\n",
      "181236: reward: -103.00, mean_100: -82.41, episodes: 1296, epsilon: 0.010\n",
      "181316: reward: -79.00, mean_100: -82.45, episodes: 1297, epsilon: 0.010\n",
      "181387: reward: -70.00, mean_100: -82.12, episodes: 1298, epsilon: 0.010\n",
      "181479: reward: -91.00, mean_100: -82.34, episodes: 1299, epsilon: 0.010\n",
      "181554: reward: -74.00, mean_100: -82.07, episodes: 1300, epsilon: 0.010\n",
      "181555: reward: 0.00, mean_100: -82.01, episodes: 1301, epsilon: 0.010\n",
      "181624: reward: -68.00, mean_100: -81.93, episodes: 1302, epsilon: 0.010\n",
      "181702: reward: -77.00, mean_100: -82.08, episodes: 1303, epsilon: 0.010\n",
      "181773: reward: -70.00, mean_100: -82.15, episodes: 1304, epsilon: 0.010\n",
      "181844: reward: -70.00, mean_100: -81.45, episodes: 1305, epsilon: 0.010\n",
      "181912: reward: -67.00, mean_100: -81.38, episodes: 1306, epsilon: 0.010\n",
      "181982: reward: -69.00, mean_100: -81.32, episodes: 1307, epsilon: 0.010\n",
      "182093: reward: -110.00, mean_100: -81.56, episodes: 1308, epsilon: 0.010\n",
      "182168: reward: -74.00, mean_100: -81.60, episodes: 1309, epsilon: 0.010\n",
      "182245: reward: -76.00, mean_100: -81.40, episodes: 1310, epsilon: 0.010\n",
      "182344: reward: -98.00, mean_100: -81.50, episodes: 1311, epsilon: 0.010\n",
      "182433: reward: -88.00, mean_100: -81.63, episodes: 1312, epsilon: 0.010\n",
      "182503: reward: -69.00, mean_100: -81.25, episodes: 1313, epsilon: 0.010\n",
      "182600: reward: -96.00, mean_100: -81.47, episodes: 1314, epsilon: 0.010\n",
      "182670: reward: -69.00, mean_100: -81.45, episodes: 1315, epsilon: 0.010\n",
      "182751: reward: -80.00, mean_100: -81.38, episodes: 1316, epsilon: 0.010\n",
      "182815: reward: -63.00, mean_100: -81.00, episodes: 1317, epsilon: 0.010\n",
      "182878: reward: -62.00, mean_100: -80.71, episodes: 1318, epsilon: 0.010\n",
      "182967: reward: -88.00, mean_100: -80.75, episodes: 1319, epsilon: 0.010\n",
      "183037: reward: -69.00, mean_100: -80.74, episodes: 1320, epsilon: 0.010\n",
      "183130: reward: -92.00, mean_100: -81.02, episodes: 1321, epsilon: 0.010\n",
      "183212: reward: -81.00, mean_100: -80.81, episodes: 1322, epsilon: 0.010\n",
      "183283: reward: -70.00, mean_100: -80.77, episodes: 1323, epsilon: 0.010\n",
      "183360: reward: -76.00, mean_100: -80.84, episodes: 1324, epsilon: 0.010\n",
      "183430: reward: -69.00, mean_100: -80.82, episodes: 1325, epsilon: 0.010\n",
      "183512: reward: -81.00, mean_100: -80.35, episodes: 1326, epsilon: 0.010\n",
      "183600: reward: -87.00, mean_100: -80.29, episodes: 1327, epsilon: 0.010\n",
      "183700: reward: -99.00, mean_100: -80.53, episodes: 1328, epsilon: 0.010\n",
      "183770: reward: -69.00, mean_100: -80.49, episodes: 1329, epsilon: 0.010\n",
      "183840: reward: -69.00, mean_100: -80.30, episodes: 1330, epsilon: 0.010\n",
      "183919: reward: -78.00, mean_100: -80.45, episodes: 1331, epsilon: 0.010\n",
      "184036: reward: -116.00, mean_100: -80.65, episodes: 1332, epsilon: 0.010\n",
      "184100: reward: -63.00, mean_100: -80.39, episodes: 1333, epsilon: 0.010\n",
      "184173: reward: -72.00, mean_100: -80.17, episodes: 1334, epsilon: 0.010\n",
      "184245: reward: -71.00, mean_100: -79.92, episodes: 1335, epsilon: 0.010\n",
      "Solved in 184245 steps!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "REPLAY_SIZE = 100000\n",
    "TARGET_UPDATE_FREQ = 1000\n",
    "MAX_EPISODES = 10000\n",
    "SOLVED_REWARD = -80\n",
    "\n",
    "class DuelingDQN(nn.Module):\n",
    "    def __init__(self, input_size, n_actions):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128)\n",
    "        )\n",
    "        \n",
    "        self.advantage = nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "        \n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.shared(x)\n",
    "        advantage = self.advantage(x)\n",
    "        value = self.value(x)\n",
    "        return value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "\n",
    "def record_episode(env, net, device, save_path):\n",
    "    \"\"\"Record a single episode and save it.\"\"\"\n",
    "    import cv2\n",
    "    obs, _ = env.reset()\n",
    "    frames = []\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        state_v = torch.FloatTensor([obs]).to(device)\n",
    "        with torch.no_grad():\n",
    "            q_vals = net(state_v)\n",
    "            action = torch.argmax(q_vals).item()\n",
    "        \n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        frame = env.render()\n",
    "        if frame is not None:  # Ensure we have a valid frame\n",
    "            # Resize to dimensions divisible by 16\n",
    "            h, w = frame.shape[:2]\n",
    "            new_h = ((h + 15) // 16) * 16\n",
    "            new_w = ((w + 15) // 16) * 16\n",
    "            frame = cv2.resize(frame, (new_w, new_h))\n",
    "            frames.append(frame)\n",
    "    \n",
    "    if frames:  # Only save if we have frames\n",
    "        imageio.mimsave(save_path, frames, fps=30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"Acrobot-v1\", render_mode=\"rgb_array\")\n",
    "    \n",
    "    if not os.path.exists(\"./training_loop\"):\n",
    "        os.makedirs(\"./training_loop\")\n",
    "\n",
    "    net = DuelingDQN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
    "    tgt_net = DuelingDQN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
    "    tgt_net.load_state_dict(net.state_dict())\n",
    "    \n",
    "    print(net)\n",
    "    \n",
    "    buffer = []\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "    total_rewards = []\n",
    "    step_idx = 0\n",
    "    done_episodes = 0\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    curr_reward = 0\n",
    "    epsilon = 1.0\n",
    "\n",
    "    while True:\n",
    "        step_idx += 1\n",
    "        epsilon = max(0.01, 1.0 - step_idx / 100000)\n",
    "\n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            state_v = torch.FloatTensor([obs]).to(device)\n",
    "            q_vals = net(state_v)\n",
    "            action = torch.argmax(q_vals).item()\n",
    "\n",
    "        next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        curr_reward += reward\n",
    "        \n",
    "        buffer.append((obs, action, reward, next_obs, done))\n",
    "        if len(buffer) > REPLAY_SIZE:\n",
    "            buffer.pop(0)\n",
    "\n",
    "        if done:\n",
    "            obs, _ = env.reset()\n",
    "            total_rewards.append(curr_reward)\n",
    "            curr_reward = 0\n",
    "            done_episodes += 1\n",
    "            \n",
    "            mean_reward = float(np.mean(total_rewards[-100:]))\n",
    "            print(f\"{step_idx}: reward: {total_rewards[-1]:.2f}, mean_100: {mean_reward:.2f}, episodes: {done_episodes}, epsilon: {epsilon:.3f}\")\n",
    "\n",
    "            if done_episodes % 100 == 0:\n",
    "                record_episode(\n",
    "                    env,\n",
    "                    net,\n",
    "                    device,\n",
    "                    f\"./training_loop/episode_{done_episodes}.mp4\"\n",
    "                )\n",
    "\n",
    "            if mean_reward > SOLVED_REWARD:\n",
    "                print(f\"Solved in {step_idx} steps!\")\n",
    "                record_episode(\n",
    "                    env,\n",
    "                    net,\n",
    "                    device,\n",
    "                    f\"./training_loop/solved_episode.mp4\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "            if done_episodes >= MAX_EPISODES:\n",
    "                print(f\"Stopping after {MAX_EPISODES} episodes\")\n",
    "                break\n",
    "        else:\n",
    "            obs = next_obs\n",
    "\n",
    "        if len(buffer) < BATCH_SIZE:\n",
    "            continue\n",
    "\n",
    "        batch_indices = np.random.choice(len(buffer), BATCH_SIZE, replace=False)\n",
    "        batch = [buffer[idx] for idx in batch_indices]\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        states_v = torch.FloatTensor(states).to(device)\n",
    "        actions_v = torch.LongTensor(actions).to(device)\n",
    "        rewards_v = torch.FloatTensor(rewards).to(device)\n",
    "        next_states_v = torch.FloatTensor(next_states).to(device)\n",
    "        done_mask = torch.BoolTensor(dones).to(device)\n",
    "\n",
    "        state_action_values = net(states_v).gather(1, actions_v.unsqueeze(-1)).squeeze(-1)\n",
    "        with torch.no_grad():\n",
    "            next_state_values = tgt_net(next_states_v).max(1)[0]\n",
    "            next_state_values[done_mask] = 0.0\n",
    "            expected_state_action_values = rewards_v + GAMMA * next_state_values\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_v = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step_idx % TARGET_UPDATE_FREQ == 0:\n",
    "            tgt_net.load_state_dict(net.state_dict())\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb84878-2730-4172-b60b-665b3328f5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a79f4-7435-4e27-9019-fa9c6f024d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
